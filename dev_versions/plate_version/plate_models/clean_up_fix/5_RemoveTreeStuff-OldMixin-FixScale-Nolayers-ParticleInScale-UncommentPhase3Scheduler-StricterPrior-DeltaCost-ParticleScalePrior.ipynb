{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe491f-acab-469c-90c9-4fb859e695fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# various import statements\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import cluster\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import inspect\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus, softmax\n",
    "from torch.distributions import constraints\n",
    "import seaborn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import pyro.optim\n",
    "from pyro.infer import SVI\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "sc.settings.figdir=os.path.expanduser('~/WbFigures/SpeciesDivergenceNoScaling')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ede1a-5159-40ae-bb51-f03a129f7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata=sc.read_h5ad(os.path.expanduser('/home/matthew.schmitz/Matthew/data/cortex_data/v1_combination.h5ad'),backed='r')\n",
    "# adata=adata[~adata.obs['dataset'].isin(['jorstad_cross_areal','krienen_marmoset']),:]\n",
    "# adata.write_h5ad(os.path.expanduser('/home/matthew.schmitz/Matthew/data/cortex_data/v1_combination_nojo.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a282e6-78c4-4e8a-8ac0-e1db80319c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad(os.path.expanduser('/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/data/taxtest/HvQvM/HvQvMall.h5ad'),backed='r')\n",
    "\n",
    "adata.obsm[\"X_original_umap\"]=adata.obsm[\"X_umap\"]\n",
    "sc.pl.umap(adata,color='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c61df-51ad-4d4b-b5b6-39fd5d1e4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/')\n",
    "import antipode_model\n",
    "from antipode_model import *\n",
    "import model_functions\n",
    "from model_functions import *\n",
    "import model_distributions\n",
    "from model_distributions import *\n",
    "import model_modules\n",
    "from model_modules import *\n",
    "import train_utils\n",
    "from train_utils import *\n",
    "import plotting\n",
    "from plotting import *\n",
    "\n",
    "import importlib\n",
    "antipode_model=importlib.reload(antipode_model)\n",
    "from antipode_model import *\n",
    "\n",
    "import importlib\n",
    "model_modules=importlib.reload(model_modules)\n",
    "from model_modules import *\n",
    "\n",
    "model_functions=importlib.reload(model_functions)\n",
    "from model_functions import *\n",
    "\n",
    "import importlib\n",
    "model_distributions=importlib.reload(model_distributions)\n",
    "from model_distributions import *\n",
    "\n",
    "import importlib\n",
    "train_utils=importlib.reload(train_utils)\n",
    "from train_utils import *\n",
    "\n",
    "import importlib\n",
    "plotting=importlib.reload(plotting)\n",
    "from plotting import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3ef7d-d676-44ad-b4d4-eade22dfc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntipodeTrainingMixin:\n",
    "    '''\n",
    "    Mixin class providing functions to actually run ANTIPODE\n",
    "    can use supervised particleomy by training only phase2\n",
    "    '''\n",
    "    \n",
    "    def save_params_to_uns(self,prefix=''):\n",
    "        pstore=param_store_to_numpy()\n",
    "        pstore={n:pstore[n] for n in pstore.keys() if not re.search('encoder|classifier',n)}\n",
    "        self.adata_manager.adata.uns[prefix+'param_store']=pstore\n",
    "\n",
    "    def get_antipode_outputs(self,batch_size=2048,device='cuda'):\n",
    "        if 'species_onehot' not in self.adata_manager.adata.obsm.keys():\n",
    "            self.adata_manager.adata.obsm['species_onehot']=numpy_onehot(self.adata_manager.adata.obs['species'].cat.codes)\n",
    "        self.adata_manager.register_new_fields([scvi.data.fields.ObsmField('species_onehot','species_onehot')])\n",
    "    \n",
    "        field_types={\"s\":np.float32,\"species_onehot\":np.float32}\n",
    "        dataloader=scvi.dataloaders.AnnDataLoader(self.adata_manager,batch_size=32,drop_last=False,shuffle=False,data_and_attributes=field_types)#supervised_field_types for supervised step \n",
    "        encoder_outs=batch_output_from_dataloader(dataloader,self.zl_encoder,batch_size=batch_size,device=device)\n",
    "        encoder_outs[0]=self.z_transform(encoder_outs[0])\n",
    "        encoder_out=[x.detach().cpu().numpy() for x in encoder_outs]\n",
    "        classifier_outs=batch_torch_outputs([(self.z_transform(encoder_outs[0]))],self.classifier,batch_size=batch_size,device='cuda')\n",
    "        classifier_out=[x.detach().cpu().numpy() for x in classifier_outs]\n",
    "        bernoulli_outs=batch_torch_outputs([(self.z_transform(encoder_outs[0]))],self.bernoulator,batch_size=batch_size,device='cuda')\n",
    "        bernoulli_out=[x.detach().cpu().numpy() for x in bernoulli_outs]\n",
    "        return encoder_out,classifier_out,bernoulli_out\n",
    "    \n",
    "    def store_outputs(self,device='cuda',prefix=''):\n",
    "        self.save_params_to_uns(prefix='')\n",
    "        self.to('cpu')\n",
    "        self.eval()\n",
    "        antipode_outs=self.get_antipode_outputs(batch_size=2048,device=device)\n",
    "        particle=antipode_outs[1][0]\n",
    "        self.adata_manager.adata.obsm[prefix+'X_antipode']=antipode_outs[0][0]\n",
    "        self.adata_manager.adata.obsm[prefix+'bernoullis']=antipode_outs[2][0]\n",
    "        self.adata_manager.adata.obs[prefix+'psi']=antipode_outs[1][1]\n",
    "        self.adata_manager.adata.obs[prefix+'antipode_cluster'] = antipode_outs[1][0].argmax(1)\n",
    "        self.adata_manager.adata.obs[prefix+'antipode_cluster'] = self.adata_manager.adata.obs[prefix+'antipode_cluster'].astype(str)\n",
    "\n",
    "    def fix_scale_factor(self,svi,x,ideal_val=0.01):\n",
    "        o1=svi.evaluate_loss(*x)\n",
    "        s1=self.scale_factor\n",
    "        s2=ideal_val*s1/o1\n",
    "        self.scale_factor=s2\n",
    "    \n",
    "    def train_phase_1(self,max_steps,print_every=10000,device='cuda',max_learning_rate=0.001,num_particles=3,one_cycle_lr=True,steps=0,batch_size=32):\n",
    "        #particle phase\n",
    "        steps=steps\n",
    "        print(self.fields)\n",
    "        print(self.field_types)\n",
    "        dataloader=scvi.dataloaders.AnnDataLoader(self.adata_manager,batch_size=32,drop_last=True,shuffle=True,data_and_attributes=self.field_types)#supervised_field_types for supervised step\n",
    "        scheduler=pyro.optim.OneCycleLR({'max_lr':max_learning_rate,'total_steps':max_steps,'div_factor':100,'optim_args':{},'optimizer':torch.optim.Adam}) if one_cycle_lr else pyro.optim.ClippedAdam({'lr':max_learning_rate,'lrd':(1-(5e-6))})\n",
    "        elbo = pyro.infer.JitTrace_ELBO(num_particles=num_particles,strict_enumeration_warning=False)\n",
    "        svi = SVI(self.model, self.guide, scheduler, elbo)\n",
    "        self.train()\n",
    "        self.zl_encoder.train()\n",
    "        \n",
    "        self=self.to(device)\n",
    "        self.set_approx(True)\n",
    "        self.losses=[]\n",
    "        pbar = tqdm.tqdm(total=max_steps, position=0)\n",
    "        done=False\n",
    "        while steps < max_steps:\n",
    "            for x in dataloader:\n",
    "                x['step']=torch.ones(1).to(device)*steps\n",
    "                x=[x[k].to(device) if k in x.keys() else torch.zeros(1) for k in self.args]\n",
    "                if self.scale_factor==1.:\n",
    "                    self.fix_scale_factor(svi,x)\n",
    "                loss=svi.step(*x)\n",
    "                steps+=1\n",
    "                if steps<max_steps-1:\n",
    "                    if one_cycle_lr:\n",
    "                        scheduler.step()\n",
    "                else:\n",
    "                    break\n",
    "                pbar.update(1)\n",
    "                self.losses.append(loss)\n",
    "                if steps%print_every == 0:\n",
    "                    # Tell the scheduler we've done one epoch.\n",
    "                    pbar.write(\"[Step %02d]  Loss: %.5f\" % (steps, np.mean(self.losses[-print_every:])))\n",
    "        \n",
    "        pbar.close()\n",
    "        allDone()\n",
    "        print(\"Finished training!\")\n",
    "        return(self.losses)\n",
    "\n",
    "    def prepare_phase_2(self,cluster='kmeans'):\n",
    "        '''Run this if not running in supervised only mode (JUST phase2 with provided obsm clustering), \n",
    "        runs kmeans if cluster=kmeans, else uses the obs column provided by cluster'''\n",
    "        if cluster=='kmeans':\n",
    "            kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=self.num_labels,init='k-means++',max_iter=1000,reassignment_ratio=0.001,n_init=100,random_state=0).fit(self.adata_manager.adata.obsm['X_antipode'])\n",
    "            self.adata_manager.adata.obs['kmeans']=kmeans.labels_\n",
    "            self.adata_manager.adata.obs['kmeans']=self.adata_manager.adata.obs['kmeans'].astype(int).astype('category')\n",
    "            self.adata_manager.adata.obsm['kmeans_onehot']=numpy_onehot(self.adata_manager.adata.obs['kmeans'].cat.codes,num_classes=self.num_labels)\n",
    "        else:\n",
    "            self.adata_manager.adata.obs[cluster]=self.adata_manager.adata.obs[cluster].astype('category')\n",
    "            self.adata_manager.adata.obsm[cluster+'_onehot']=numpy_onehot(self.adata_manager.adata.obs[cluster].cat.codes,num_classes=self.num_labels)\n",
    "        new_logits=torch.tensor(group_aggr_anndata(self.adata_manager.adata,[cluster], agg_func=np.mean,layer='bernoullis',obsm=True)[0]).float()\n",
    "        pyro.get_param_store().__setitem__('taxon_mu',new_logits.to(pyro.param('locs').device))\n",
    "        new_std=torch.tensor(group_aggr_anndata(self.adata_manager.adata,[cluster], agg_func=np.std,layer='bernoullis',obsm=True)[0]).float()\n",
    "        pyro.get_param_store().__setitem__('taxon_sigma',new_std.to(pyro.param('locs').device))   \n",
    "        self.adata_manager.adata.obs[cluster]=self.adata_manager.adata.obs[cluster].astype(str).astype('category')\n",
    "        \n",
    "    def train_phase_2(self,max_steps, taxon_label='kmeans_onehot', print_every=10000, device='cuda', max_learning_rate=0.001, num_particles=1, one_cycle_lr=False, steps=0, batch_size=32):\n",
    "        '''empirically works best and fastest with one_cycle_lr=False'''\n",
    "        steps=steps\n",
    "        supervised_field_types=self.field_types.copy()\n",
    "        supervised_fields=self.fields.copy()\n",
    "        supervised_field_types[\"taxon\"]=np.float32\n",
    "        self.adata_manager.register_new_fields([make_field('taxon',('obsm',taxon_label))])\n",
    "        class_dataloader=scvi.dataloaders.AnnDataLoader(self.adata_manager, batch_size=batch_size, drop_last=True, shuffle=True, data_and_attributes=supervised_field_types)\n",
    "        scheduler=pyro.optim.OneCycleLR({'max_lr':max_learning_rate,'total_steps':max_steps, 'div_factor':100,'optim_args':{},'optimizer':torch.optim.Adam}) if one_cycle_lr else pyro.optim.ClippedAdam({'lr':max_learning_rate,'lrd':(1-(5e-6))})\n",
    "        elbo = pyro.infer.JitTraceEnum_ELBO(num_particles=num_particles,strict_enumeration_warning=False)\n",
    "        svi = SVI(self.model, self.guide, scheduler, elbo)\n",
    "        \n",
    "        self.train()\n",
    "        self=self.to(device)\n",
    "        self.set_approx(False)\n",
    "        self.losses=[]\n",
    "        #for steps in range(max_steps):\n",
    "        pbar = tqdm.tqdm(total=max_steps, position=0)\n",
    "        done=False\n",
    "        while steps < max_steps:\n",
    "            for x in class_dataloader:\n",
    "                x['step']=torch.ones(1).to(device)*steps\n",
    "                x=[x[k].to(device) if k in x.keys() else torch.zeros(1) for k in self.args]\n",
    "                if self.scale_factor==1.:\n",
    "                    self.fix_scale_factor(svi,x)\n",
    "                loss=svi.step(*x)\n",
    "                steps+=1\n",
    "                if steps<=max_steps-1:\n",
    "                    if one_cycle_lr:\n",
    "                        scheduler.step()\n",
    "                    pass\n",
    "                else:\n",
    "                    break\n",
    "                pbar.update(1)\n",
    "                self.losses.append(loss)\n",
    "                if steps%print_every == 0:\n",
    "                    # Tell the scheduler we've done one epoch.\n",
    "                    pbar.write(\"[Step %02d]  Loss: %.5f\" % (steps, np.mean(self.losses[-print_every:])))\n",
    "        \n",
    "        pbar.close()\n",
    "        allDone()\n",
    "        print(\"Finished training!\")\n",
    "        return(self.losses)\n",
    "        \n",
    "    def train_phase_3(self,max_steps,print_every=10000,device='cuda',max_learning_rate=2e-5,num_particles=3,one_cycle_lr=True,steps=0,batch_size=32):\n",
    "        '''Too high of learning rate may cause model to explode and most clusters to collapse'''\n",
    "        steps=steps\n",
    "        dataloader=scvi.dataloaders.AnnDataLoader(self.adata_manager,batch_size=batch_size,drop_last=True,shuffle=True,data_and_attributes=self.field_types)#supervised_field_types for supervised step\n",
    "        scheduler=pyro.optim.OneCycleLR({'max_lr':max_learning_rate,'total_steps':max_steps,'div_factor':100,'optim_args':{},'optimizer':torch.optim.Adam}) if one_cycle_lr else pyro.optim.ClippedAdam({'lr':max_learning_rate,'lrd':(1-(5e-6))})\n",
    "        elbo = pyro.infer.JitTraceEnum_ELBO(num_particles=num_particles,strict_enumeration_warning=False)\n",
    "        svi = SVI(self.model, self.guide, scheduler, elbo)\n",
    "\n",
    "        self.losses=[]\n",
    "        self.train()\n",
    "        self=self.to(device)\n",
    "        self.set_approx(False)\n",
    "        \n",
    "        #for steps in range(max_steps):\n",
    "        pbar = tqdm.tqdm(total=max_steps, position=0)\n",
    "        done=False\n",
    "        while steps < max_steps:\n",
    "            for x in dataloader:\n",
    "                x['step']=torch.ones(1).to(device)*steps\n",
    "                x=[x[k].to(device) if k in x.keys() else torch.zeros(1) for k in self.args]\n",
    "                if self.scale_factor==1.:\n",
    "                    self.fix_scale_factor(svi,x)\n",
    "                loss=svi.step(*x)\n",
    "                steps+=1\n",
    "                if steps<max_steps-1:\n",
    "                    if one_cycle_lr:\n",
    "                        scheduler.step()\n",
    "                        pass\n",
    "                    pass\n",
    "                else:\n",
    "                    break\n",
    "                pbar.update(1)\n",
    "                self.losses.append(loss)\n",
    "                if steps%print_every == 0:\n",
    "                    # Tell the scheduler we've done one epoch.\n",
    "                    pbar.write(\"[Step %02d]  Loss: %.5f\" % (steps, np.mean(self.losses[-print_every:])))\n",
    "        \n",
    "        pbar.close()\n",
    "        allDone()\n",
    "        print(\"Finished training!\")\n",
    "        return(self.losses)\n",
    "\n",
    "\n",
    "class ANTIPODE(PyroBaseModuleClass,AntipodeTrainingMixin):#\n",
    "    '''\n",
    "    ANTIPODE (Single Cell Ancestral Node particleomy Inference by Parcellation of Differential Expression) \n",
    "    is a variational inference model developed for the simultaneous analysis (DE) and \n",
    "    categorization (particleomy generation) of cell types across evolution (or now any covariate) using single-cell RNA-seq data.\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): An AnnData object containing the single-cell dataset.\n",
    "    discov_pair (tuple): A tuple indicating the key and location of the discovery covariate \n",
    "                         in the AnnData object. Format: ('key', 'location'), where location is \n",
    "                         either 'obs' or 'obsm'.\n",
    "    batch_pair (tuple): A tuple indicating the key and location of the batch covariate \n",
    "                        in the AnnData object. Format: ('key', 'location'), where location is \n",
    "                        either 'obs' or 'obsm'.\n",
    "    num_var (int): Number of variables (features) in the dataset.\n",
    "    num_latent (int, optional): Number of latent dimensions. Defaults to 50.\n",
    "    scale_factor (float, optional): Scaling factor for data normalization. If None, it is inferred from the data.\n",
    "    prior_scale (float, optional): Scale of the Laplace prior distributions. Defaults to 100.\n",
    "    dcd_prior (float, optional): Scale of the prior for the decoder. If None, defaults to a specific inferred value.\n",
    "    theta_prior (float, optional): Init value for the inverse dispersion of the negative binomial.\n",
    "    decay_function (callable, optional): A function that defines the decay of certain parameters over iterations.\n",
    "    max_strictness (float, optional): Maximum strictness parameter for tree convergence. Defaults to 1.\n",
    "    num_batch_embed (int, optional): Number of batch embeddings. Defaults to 10.\n",
    "    classifier_hidden (list of int, optional): Sizes of hidden layers for the classifier network. Defaults to [3000, 3000, 3000].\n",
    "    encoder_hidden (list of int, optional): Sizes of hidden layers for the encoder network. Defaults to [6000, 5000, 3000, 1000].\n",
    "    '''\n",
    "    def __init__(self, adata, discov_pair, batch_pair, layer, \n",
    "                 num_latent=50, num_labels=50,num_particles=50, scale_factor=None, prior_scale=100,dcd_prior=None,use_psi=True,loc_as_param=False,zdw_as_param=False,\n",
    "                 decay_function=None, max_strictness=1., num_batch_embed=10,theta_prior=50.,scale_init_val=0.01,\n",
    "                 classifier_hidden=[3000,3000,3000],encoder_hidden=[6000,5000,3000,1000],z_transform=None):\n",
    "\n",
    "        pyro.clear_param_store()\n",
    "\n",
    "        # Determine num_discov and num_batch from the AnnData object\n",
    "        self.discov_loc, self.discov_key = discov_pair\n",
    "        self.batch_loc, self.batch_key = batch_pair\n",
    "        self.num_discov = adata.obsm[self.discov_key].shape[-1] if self.discov_loc == 'obsm' else len(adata.obs[self.discov_key].unique())\n",
    "        self.num_batch = adata.obsm[self.batch_key].shape[-1] if self.batch_loc == 'obsm' else len(adata.obs[self.batch_key].unique())\n",
    "        self.design_matrix = (self.discov_loc == 'obsm')\n",
    "        self.layer=layer\n",
    "\n",
    "        self._setup_adata_manager_store: dict[str, type[scvi.data.AnnDataManager]] = {}\n",
    "        self.num_var = adata.layers[layer].shape[-1]\n",
    "        self.num_latent = num_latent\n",
    "        self.scale_factor = 1.0#scale_factor if scale_factor is not None else 2e2 / (self.num_var * num_particles * num_latent)\n",
    "        self.num_particles= num_particles\n",
    "        self.num_batch_embed = num_batch_embed\n",
    "        self.max_strictness = 1.\n",
    "        self.decay_function = gen_linear_function(2,1) if decay_function is None else decay_function \n",
    "        self.temperature = 0.1\n",
    "        self.epsilon = 0.006\n",
    "        self.approx = False\n",
    "        self.prior_scale = prior_scale\n",
    "        self.use_psi=use_psi\n",
    "        self.loc_as_param=loc_as_param\n",
    "        self.zdw_as_param=zdw_as_param\n",
    "        self.theta_prior=theta_prior\n",
    "        self.scale_init_val=scale_init_val\n",
    "        self.leaf_scale_only=False\n",
    "        self.num_labels=num_labels\n",
    "        \n",
    "        self.dcd_prior=torch.zeros((self.num_discov,self.num_var)) if dcd_prior is None else dcd_prior#Use this for \n",
    "        \n",
    "        # Initialize plates to be used during sampling\n",
    "        self.var_plate=pyro.plate('var_plate',self.num_var,dim=-1)\n",
    "        self.discov_plate=pyro.plate('discov_plate',self.num_discov,dim=-3)\n",
    "        self.batch_plate=pyro.plate('batch_plate',self.num_batch,dim=-3)\n",
    "        self.latent_plate=pyro.plate('latent_plate',self.num_latent,dim=-1)\n",
    "        self.latent_plate2=pyro.plate('latent_plate2',self.num_latent,dim=-2)\n",
    "        self.particle_plate=pyro.plate('particle_plate',self.num_particles,dim=-2)\n",
    "        self.label_plate=pyro.plate('label_plate',self.num_labels,dim=-2)\n",
    "        self.batch_embed_plate=pyro.plate('batch_embed_plate',self.num_batch_embed,dim=-3)\n",
    "\n",
    "        #Initialize MAP inference modules\n",
    "        self.dm=MAPLaplaceModule(self,'discov_dm',[self.num_discov,self.num_particles,self.num_latent],[self.discov_plate,self.particle_plate,self.latent_plate])\n",
    "        self.bm=MAPLaplaceModule(self,'batch_dm',[self.num_batch,self.num_particles,self.num_latent],[self.batch_plate,self.particle_plate,self.latent_plate])\n",
    "        self.di=MAPLaplaceModule(self,'discov_di',[self.num_discov,self.num_particles,self.num_var],[self.discov_plate,self.particle_plate,self.var_plate])\n",
    "        self.bei=MAPLaplaceModule(self,'batch_di',[self.num_batch_embed,self.num_particles,self.num_var],[self.batch_embed_plate,self.particle_plate,self.var_plate])\n",
    "        self.ci=MAPLaplaceModule(self,'cluster_intercept',[self.num_particles, self.num_var],[self.particle_plate,self.var_plate])\n",
    "        self.dc=MAPLaplaceModule(self,'discov_dc',[self.num_discov,self.num_latent,self.num_var],[self.discov_plate,self.latent_plate2,self.var_plate])\n",
    "        self.zdw=MAPLaplaceModule(self,'z_decoder_weight',[self.num_latent,self.num_var],[self.latent_plate2,self.var_plate],init_val=((2/self.num_latent)*(torch.rand(self.num_latent,self.num_var)-0.5)),param_only=self.zdw_as_param)\n",
    "        self.zl=MAPLaplaceModule(self,'locs',[self.num_particles,self.num_latent],[self.particle_plate,self.latent_plate],param_only=self.loc_as_param)\n",
    "        self.zs=MAPLaplaceModule(self,'scales',[self.num_particles,self.num_latent],[self.particle_plate,self.latent_plate],init_val=self.scale_init_val*torch.ones(self.num_particles,self.num_latent),constraint=constraints.positive,param_only=False)\n",
    "        self.zld=MAPLaplaceModule(self,'locs_dynam',[self.num_labels,self.num_latent],[self.label_plate,self.latent_plate],param_only=False)\n",
    "        #self.taxon_particles=MAPLaplaceModule(self,'taxon_particles',[self.num_labels,self.num_particles],[],param_only=True)\n",
    "        self.taxon_mu=MAPLaplaceModule(self,'taxon_mu',[self.num_labels,self.num_particles],[],param_only=True)\n",
    "        self.taxon_sigma=MAPLaplaceModule(self,'taxon_sigma',[self.num_labels,self.num_particles],[],init_val=0.5*torch.ones(self.num_labels,self.num_particles),constraint=constraints.positive,param_only=False)\n",
    "        \n",
    "        self.z_transform=null_function if z_transform is None else z_transform#centered_sigmoid#torch.special.expit\n",
    "\n",
    "        if self.design_matrix:\n",
    "            fields={'s':('layers',self.layer),\n",
    "            'discov_ind':('obsm',self.discov_key),\n",
    "            'batch_ind':('obsm',self.batch_key)}\n",
    "            field_types={\"s\":np.float32,\"batch_ind\":np.float32,\"discov_ind\":np.float32}\n",
    "        else:\n",
    "            fields={'s':('layers',self.layer),\n",
    "            'discov_ind':('obs',self.discov_key),\n",
    "            'batch_ind':('obs',self.batch_key)}\n",
    "            field_types={\"s\":np.float32,\"batch_ind\":np.int64,\"discov_ind\":np.int64}\n",
    "\n",
    "        self.fields=fields\n",
    "        self.field_types=field_types\n",
    "        self.setup_anndata(adata, {'discov_ind': discov_pair, 'batch_ind': batch_pair}, self.field_types)\n",
    "        \n",
    "        super().__init__()\n",
    "        # Setup the various neural networks used in the model and guide\n",
    "        self.z_decoder=ZDecoder(num_latent=self.num_latent, num_var=self.num_var, hidden_dims=[])        \n",
    "        self.zl_encoder=ZLEncoder(num_var=self.num_var,hidden_dims=encoder_hidden,num_cat_input=self.num_discov,\n",
    "                    outputs=[(self.num_latent,None),(self.num_latent,softplus)])\n",
    "\n",
    "        self.bernoulator=Classifier(num_latent=self.num_latent,hidden_dims=[2000,2000,2000],\n",
    "                    outputs=[(self.num_particles,None),(self.num_particles,softplus)])\n",
    "        \n",
    "        self.classifier=Classifier(num_latent=self.num_latent,hidden_dims=classifier_hidden,\n",
    "                    outputs=[(self.num_labels,None),(1,None),(1,softplus)])\n",
    "\n",
    "        #self.bc_nn=SimpleFFNN(in_dim=self.num_batch,hidden_dims=[200,200,50,5],\n",
    "        #            out_dim=self.num_var*self.num_latent)\n",
    "        #Too large to exactly model gene-level batch effects for all cluster x batch\n",
    "        self.be_nn=SimpleFFNN(in_dim=self.num_batch,hidden_dims=[1000,500,500],\n",
    "                    out_dim=self.num_batch_embed)\n",
    "        \n",
    "        self.epsilon = 0.006\n",
    "        #Initialize model in approximation mode\n",
    "        self.approx=False\n",
    "        self.prior_scale=prior_scale\n",
    "        self.args=inspect.getfullargspec(self.model).args[1:]#skip self\n",
    "\n",
    "    def setup_anndata(self,adata: anndata.AnnData,fields,field_types,**kwargs,):\n",
    "        \n",
    "        anndata_fields=[make_field(x,self.fields[x]) for x in self.fields.keys()]\n",
    "        \n",
    "        adata_manager = scvi.data.AnnDataManager(\n",
    "            fields=anndata_fields\n",
    "        )\n",
    "        adata_manager.register_fields(adata, **kwargs)\n",
    "        self.register_manager(adata_manager)\n",
    "        if fields['discov_ind'][0]=='obsm':\n",
    "            self.design_matrix=True\n",
    "            if fields['batch_ind'][0]!='obsm':\n",
    "                raise Exception(\"If discov is design matrix, batch must be as well!\")\n",
    "\n",
    "    def register_manager(self, adata_manager: scvi.data.AnnDataManager):\n",
    "        adata_id = adata_manager.adata_uuid\n",
    "        self._setup_adata_manager_store[adata_id] = adata_manager\n",
    "        self.adata_manager=adata_manager\n",
    "    \n",
    "    def set_approx(self,b: bool):\n",
    "        self.approx=b\n",
    "    \n",
    "    def set_leaf_scale_only(self,b: bool):\n",
    "        self.leaf_scale_only=b\n",
    "        \n",
    "    def model(self, s,discov_ind=torch.zeros(1),batch_ind=torch.zeros(1),step=torch.ones(1),taxon=torch.zeros(1)):\n",
    "        # Register various nn.Modules (i.e. the decoder/encoder networks) with Pyro\n",
    "        pyro.module(\"antipode\", self)\n",
    "\n",
    "        if not self.design_matrix:\n",
    "            batch=index_to_onehot(batch_ind,[s.shape[0],self.num_batch]).to(s.device)\n",
    "            discov=index_to_onehot(discov_ind,[s.shape[0],self.num_discov]).to(s.device)\n",
    "            batch_ind=batch_ind.squeeze()\n",
    "            discov_ind=discov_ind.squeeze()\n",
    "        else:\n",
    "            batch=batch_ind\n",
    "            discov=discov_ind\n",
    "        \n",
    "        minibatch_plate=pyro.plate(\"minibatch_plate\", s.shape[0],dim=-1)\n",
    "        minibatch_plate2=pyro.plate(\"minibatch_plate2\", s.shape[0],dim=-2)\n",
    "        cur_strictness=self.decay_function(step, self.max_strictness)\n",
    "        l = s.sum(1).unsqueeze(-1)\n",
    "        #txp=torch.sigmoid(self.taxon_particles.model_sample(s))\n",
    "        \n",
    "        # We scale all sample statements by scale_factor so that the ELBO loss function\n",
    "        # is normalized wrt the number of datapoints and genes.\n",
    "        # This helps with numerical stability during optimization.\n",
    "        with poutine.scale(scale=self.scale_factor):\n",
    "            # This gene-level parameter modulates the variance of the observation distribution\n",
    "            s_theta = pyro.param(\"s_inverse_dispersion\", self.theta_prior * s.new_ones(self.num_var),\n",
    "                               constraint=constraints.positive)\n",
    "            \n",
    "            dcd=pyro.param(\"discov_constitutive_de\", self.dcd_prior.to(s.device))\n",
    "            if not self.approx:\n",
    "                particle_mu_param=self.taxon_mu.model_sample(s)\n",
    "                particle_sigma_param=self.taxon_sigma.model_sample(s)\n",
    "            \n",
    "            with minibatch_plate:\n",
    "                beta_prior_a=1.*s.new_ones(self.num_particles)\n",
    "                beta_prior_a[0]=10.\n",
    "                if self.approx:#Bernoulli particles approx?\n",
    "                    particle_probs = pyro.sample(\"particle_probs\", dist.Beta(beta_prior_a,s.new_ones(self.num_particles),validate_args=True).to_event(1))\n",
    "                    particle = pyro.sample('particle',dist.RelaxedBernoulli(temperature=0.1*s.new_ones(1),probs=particle_probs).to_event(1))\n",
    "                    taxon=taxon_probs=s.new_ones(s.shape[0],self.num_labels)\n",
    "                else:\n",
    "                    taxon_probs=pyro.sample('taxon_probs',dist.Dirichlet(s.new_ones(s.shape[0],self.num_labels),validate_args=True))\n",
    "                    if sum(taxon.shape) > 1:\n",
    "                        print(taxon_probs.argmax(-1))\n",
    "                        print(taxon.argmax(-1))\n",
    "                        taxon = pyro.sample(\"taxon\", dist.OneHotCategorical(probs=taxon_probs,validate_args=True),obs=taxon)\n",
    "                        print(taxon.argmax(-1))\n",
    "                    else:\n",
    "                        taxon = pyro.sample(\"taxon\", dist.OneHotCategorical(probs=s.new_ones(s.shape[0],self.num_labels),validate_args=True),infer={'enumerate':'parallel'})\n",
    "                    #particle_probs=oh_index(txp,taxon)\n",
    "                    particle_mu=oh_index(particle_mu_param,taxon)\n",
    "                    particle_sigma_squared=oh_index(particle_sigma_param,taxon)\n",
    "                    #beta_a,beta_b=beta_parameters_from_mean_variance(particle_mu, particle_sigma_squared)\n",
    "                    particle_probs = safe_sigmoid(pyro.sample(\"particle_probs\", dist.Normal(particle_mu,particle_sigma_squared,validate_args=True).to_event(1)))\n",
    "                    particle = pyro.sample('particle',dist.RelaxedBernoulli(temperature=0.1*s.new_ones(1),probs=particle_probs).to_event(1))\n",
    "            \n",
    "            locs_dynam=self.zld.model_sample(s,scale=fest([taxon_probs],-1))        \n",
    "            locs=self.zl.model_sample(s,scale=fest([particle],-1))\n",
    "            scales=self.zs.model_sample(s,scale=fest([particle],-1))\n",
    "            discov_dm=self.dm.model_sample(s,scale=fest([discov,particle],-1))\n",
    "            discov_di=self.di.model_sample(s,scale=fest([discov,particle],-1))\n",
    "            batch_dm=self.bm.model_sample(s,scale=fest([batch,particle],-1))\n",
    "            batch_embed=centered_sigmoid(self.be_nn(batch))\n",
    "            bei=self.bei.model_sample(s,scale=fest([batch_embed,particle],-1))\n",
    "            cluster_intercept=self.ci.model_sample(s,scale=fest([particle],-1))\n",
    "            \n",
    "            with minibatch_plate:\n",
    "                bi=torch.einsum('...bi,...ijk->...bjk',batch_embed,bei)\n",
    "                bi=torch.einsum('...bj,...bjk->...bk',particle,bi)\n",
    "                psi = centered_sigmoid(pyro.sample('psi',dist.Laplace(s.new_zeros(s.shape[0],1),self.prior_scale*s.new_ones(s.shape[0],1)).to_event(1)))\n",
    "                psi = 0 if self.approx else psi\n",
    "                this_locs=oh_index(locs,particle)\n",
    "                this_scales=oh_index(scales,particle)\n",
    "                z=pyro.sample('z', dist.Normal(this_locs,this_scales+self.epsilon,validate_args=True).to_event(1))\n",
    "                pyro.sample('z_cost', dist.Laplace(this_locs,self.prior_scale*s.new_ones(this_locs.shape),validate_args=True).to_event(1))\n",
    "\n",
    "            cur_discov_dm = oh_index1(discov_dm, discov_ind) if self.design_matrix else discov_dm[discov_ind]\n",
    "            cur_batch_dm = oh_index1(batch_dm, batch_ind) if self.design_matrix else batch_dm[batch_ind]\n",
    "            cur_dcd = oh_index(dcd, discov) if self.design_matrix else  dcd[discov_ind]\n",
    "            if self.design_matrix:\n",
    "                z=z+oh_index2(oh_index1(discov_dm,discov_ind),particle) + oh_index2(oh_index1(batch_dm,batch_ind),particle)+(oh_index(locs_dynam,taxon)*psi)\n",
    "            else:\n",
    "                z=z+oh_index2(discov_dm[discov_ind],particle) + oh_index2(batch_dm[batch_ind],particle)+(oh_index(locs_dynam,taxon)*psi)\n",
    "            z=self.z_transform(z)\n",
    "            fake_z=oh_index(locs,particle)+oh_index2(discov_dm[discov_ind],particle) + oh_index2(batch_dm[batch_ind],particle)+(oh_index(locs_dynam,taxon_probs)*psi)\n",
    "            fake_z=self.z_transform(fake_z)\n",
    "\n",
    "            z_decoder_weight=self.zdw.model_sample(s,scale=fest([fake_z.abs()],-1))\n",
    "            discov_dc=self.dc.model_sample(s,scale=fest([discov,fake_z.abs()],-1))\n",
    "            cur_discov_di = oh_index1(discov_di, discov_ind) if self.design_matrix else discov_di[discov_ind]\n",
    "            cur_discov_dc = oh_index1(discov_dc, discov_ind) if self.design_matrix else discov_dc[discov_ind]\n",
    "            cur_discov_di=oh_index2(cur_discov_di,particle)\n",
    "            cur_cluster_intercept=oh_index(cluster_intercept,particle)\n",
    "            \n",
    "            mu=torch.einsum('...bi,...bij->...bj',z,z_decoder_weight+cur_discov_dc)#+bc\n",
    "            spliced_mu=mu+cur_dcd+cur_discov_di+cur_cluster_intercept+bi\n",
    "            spliced_out=torch.softmax(spliced_mu,dim=-1)\n",
    "            log_mu = (l * spliced_out + 1e-6).log()\n",
    "            \n",
    "            with self.var_plate,minibatch_plate2:\n",
    "                s_dist = dist.NegativeBinomial(total_count=s_theta,logits=log_mu-s_theta.log(),validate_args=True)\n",
    "                s_out=pyro.sample(\"s\", s_dist, obs=s.int())\n",
    "\n",
    "    \n",
    "    # The guide specifies the variational distribution\n",
    "    def guide(self, s,discov_ind=torch.zeros(1),batch_ind=torch.zeros(1),step=torch.ones(1),taxon=torch.zeros(1)):\n",
    "        pyro.module(\"antipode\", self)\n",
    "        \n",
    "        if not self.design_matrix:\n",
    "            batch=index_to_onehot(batch_ind,[s.shape[0],self.num_batch]).to(s.device)\n",
    "            discov=index_to_onehot(discov_ind,[s.shape[0],self.num_discov]).to(s.device)\n",
    "            batch_ind=batch_ind.squeeze()\n",
    "            discov_ind=discov_ind.squeeze()\n",
    "        else:\n",
    "            batch=batch_ind\n",
    "            discov=discov_ind\n",
    "        \n",
    "        minibatch_plate=pyro.plate(\"minibatch_plate\", s.shape[0])\n",
    "        cur_strictness=self.decay_function(step, self.max_strictness)\n",
    "        \n",
    "        with poutine.scale(scale=self.scale_factor):\n",
    "            with minibatch_plate:\n",
    "                z_loc, z_scale= self.zl_encoder(s,discov)\n",
    "                z=pyro.sample('z',dist.Normal(z_loc,z_scale+self.epsilon).to_event(1))\n",
    "                pyro.sample('z_cost',dist.Delta(z_loc).to_event(1))\n",
    "                z=self.z_transform(z)\n",
    "                taxon_logits,psi_loc,psi_scale=self.classifier(z)\n",
    "                particle_logits,particle_scale=self.bernoulator(z)\n",
    "                psi=centered_sigmoid(pyro.sample('psi',dist.Normal(psi_loc,psi_scale).to_event(1)))\n",
    "                psi = 0 if self.approx else psi\n",
    "                if self.approx:\n",
    "                    particle_dist = dist.Delta(safe_sigmoid(particle_logits),validate_args=True).to_event(1)\n",
    "                    particle_probs = pyro.sample(\"particle_probs\", particle_dist)\n",
    "                    particle = pyro.sample('particle',dist.RelaxedBernoulli(temperature=self.temperature*s.new_ones(1),probs=particle_probs).to_event(1))\n",
    "                    taxon=taxon_probs=s.new_ones(s.shape[0],self.num_labels)\n",
    "                else:\n",
    "                    taxon_probs=pyro.sample('taxon_probs',dist.Delta(safe_softmax(taxon_logits)).to_event(1))\n",
    "                    particle_dist = dist.Normal(particle_logits,particle_scale).to_event(1)\n",
    "                    particle_probs = safe_sigmoid(pyro.sample(\"particle_probs\", particle_dist))\n",
    "                    #particle_probs=safe_sigmoid(particle_logits)\n",
    "                    particle = pyro.sample('particle',dist.RelaxedBernoulli(temperature=self.temperature*s.new_ones(1),probs=particle_probs).to_event(1))\n",
    "                    if sum(taxon.shape) > 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        taxon = pyro.sample(\"taxon\", \n",
    "                                         dist.OneHotCategorical(probs=taxon_probs,validate_args=True),infer={'enumerate':'parallel'})                    \n",
    "        \n",
    "            locs_dynam=self.zld.guide_sample(s,scale=fest([taxon_probs],-1))\n",
    "            if not self.approx:\n",
    "                particle_mu_param=self.taxon_mu.guide_sample(s)\n",
    "                particle_sigma_param=self.taxon_sigma.guide_sample(s)\n",
    "            locs=self.zl.guide_sample(s,scale=fest([particle],-1))\n",
    "            scales=self.zs.guide_sample(s,scale=fest([particle],-1))\n",
    "            discov_dm=self.dm.guide_sample(s,scale=fest([discov,particle],-1))\n",
    "            batch_dm=self.bm.guide_sample(s,scale=fest([batch,particle],-1))\n",
    "            batch_embed=centered_sigmoid(self.be_nn(batch))\n",
    "            discov_di=self.di.guide_sample(s,scale=fest([discov,particle],-1))\n",
    "            cluster_intercept=self.ci.guide_sample(s,scale=fest([particle],-1))\n",
    "            bei=self.bei.guide_sample(s,scale=fest([batch_embed,particle],-1))#maybe should be abs sum bei\n",
    "            if self.design_matrix:\n",
    "                z=z+oh_index2(oh_index1(discov_dm,discov_ind),particle) + oh_index2(oh_index1(batch_dm,batch_ind),particle)+(oh_index(locs_dynam,taxon)*psi)\n",
    "            else:\n",
    "                z=z+oh_index2(discov_dm[discov_ind],particle) + oh_index2(batch_dm[batch_ind],particle)+(oh_index(locs_dynam,taxon)*psi)\n",
    "            z=self.z_transform(z)\n",
    "            fake_z=oh_index(locs,particle)+oh_index2(discov_dm[discov_ind],particle) + oh_index2(batch_dm[batch_ind],particle)+(oh_index(locs_dynam,taxon_probs)*psi)\n",
    "            fake_z=self.z_transform(fake_z)\n",
    "            z_decoder_weight=self.zdw.guide_sample(s,scale=fest([fake_z.abs()],-1))\n",
    "            discov_dc=self.dc.guide_sample(s,scale=fest([discov,fake_z.abs()],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8188b4f-93d3-417e-b6d6-061bdb88f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pyro.clear_param_store()\n",
    "    del antipode_model\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3438c5-dd7e-41aa-bde8-2183986f0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_var=adata.shape[1]\n",
    "batch_size=32\n",
    "level_sizes=[1,10,30,125]\n",
    "num_latent=150\n",
    "num_particles=sum(level_sizes)\n",
    "steps=0\n",
    "max_steps=100000\n",
    "print_every=5000\n",
    "num_labels=201\n",
    "\n",
    "# Clear Pyro param store so we don't conflict with previous run\n",
    "pyro.clear_param_store()\n",
    "# Fix random number seed to a lucky number\n",
    "pyro.util.set_rng_seed(13)\n",
    "# Enable optional validation warnings\n",
    "pyro.enable_validation(False)\n",
    "\n",
    "decay_function=gen_linear_function(max_steps,10000)#gen_exponential_decay(5e-6)\n",
    "\n",
    "# Instantiate instance of model/guide and various neural networks\n",
    "antipode_model = ANTIPODE(num_latent=num_latent,num_particles=num_particles,\n",
    "                adata=adata,discov_pair=('obs','species'),batch_pair=('obs','batch_name'),layer='spliced',loc_as_param=False,\n",
    "                scale_init_val=0.01,num_labels=num_labels,\n",
    "                decay_function=decay_function,max_strictness=100,prior_scale=10.,num_batch_embed=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181029a-beb4-4d05-bdda-3854b8fda660",
   "metadata": {},
   "source": [
    "# Training Phase 1: Particlized tree approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7be17-ca10-42bd-9b6a-deacd43f59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.train_phase_1(max_steps=max_steps,print_every=10000,num_particles=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f43078-c83f-4bf4-a86f-31f0e865c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(antipode_model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df09d64-4b95-4eb8-b5db-97943a845336",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.store_outputs(device=device,prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250db4c-2c28-4fcd-bcdb-059d8810cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmm_heatmaps(antipode_model)\n",
    "plot_d_hists(antipode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce8d82-5d92-4eb7-9abd-12c47f1379f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDE_KEY = \"X_antipode_MDE\"\n",
    "adata.obsm[MDE_KEY] = scvi.model.utils.mde(adata.obsm['X_antipode'])\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"antipode_cluster\"],legend_fontsize=6,legend_fontweight='normal',\n",
    "    legend_loc='on data',palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"species\"],palette=sc.pl.palettes.godsnot_102\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de70cb5-08f1-4fc1-86ac-dc777e7615b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "random_choice=np.random.choice(adata.obs.index,size=20000,replace=False)\n",
    "random_choice=np.where(adata.obs.index.isin(random_choice))[0]\n",
    "xdata=adata[random_choice,:]\n",
    "xdata=xdata.to_memory().copy()\n",
    "sc.pp.neighbors(xdata,n_neighbors=20, use_rep=\"X_antipode\")\n",
    "sc.tl.umap(xdata)\n",
    "sc.pl.umap(xdata,color=['species'],use_raw=False,palette=sc.pl.palettes.godsnot_102)\n",
    "sc.pl.umap(xdata,color=['psi'],use_raw=False,legend_loc='on data',cmap='coolwarm')\n",
    "sc.pl.umap(xdata,color=['antipode_cluster'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "\"\"\"\n",
    "# xdata.X=xdata.layers['UMIs']\n",
    "# sc.pp.normalize_per_cell(xdata)\n",
    "# sc.pp.log1p(xdata)\n",
    "# sc.pp.scale(xdata,max_value=10)\n",
    "#sc.pl.umap(xdata,color=['GBX2','EOMES','SIX3','OTX2','FOXG1','RBFOX3','TH','PDGFRA','AQP4','FOXJ1','AIF1','TTR','MOG','COL1A2','CD34','COL4A1','NPY','NKX2-1','FOXP2','SATB2','RORB','FEZF2','EMX1'],use_raw=False,cmap='Purples')\n",
    "#sc.pl.umap(xdata,color=['DLX2','PROX1','SCGN','TSHZ1','MEIS2','NKX2-1','LHX6','CRABP1','TSHZ1','FOXG1','PDGFRA','AIF1','AQP4','EDNRB','FOXJ1','CD34','MKI67'],cmap='Purples',use_raw=False)\n",
    "#sc.pl.umap(xdata,color=['RPL7','RPS17','RPL13A','MEF2C'],cmap='Purples',use_raw=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4ded4-2f42-456e-bbc8-9d5c0d2b178b",
   "metadata": {},
   "source": [
    "# Training Phase 2: Inintializing categorical layered tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051283f-c330-439d-95f5-ad7ae9c9d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.prepare_phase_2()\n",
    "#sc.pl.umap(adata,color=['kmeans'],legend_loc=\"on data\",palette=sc.pl.palettes.godsnot_102)\n",
    "adata.obs['kmeans']=adata.obs['kmeans'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235e252-7d5b-4d16-9ff0-02d2e8b5f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.clustermap(torch.sigmoid(pyro.param('taxon_mu')).cpu().detach().numpy())\n",
    "plt.show()\n",
    "seaborn.clustermap(pyro.param('taxon_sigma').cpu().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d710b-c5b3-460d-9c29-12f4f077043f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "antipode_model.train_phase_2(max_steps=max_steps,print_every=10000,num_particles=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c983977-6bff-42b5-8896-8596f6fbe927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(antipode_model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaebdf9-97b8-459e-be52-df9f4fe41819",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.clustermap(torch.sigmoid(pyro.param('taxon_mu')).cpu().detach().numpy())\n",
    "plt.show()\n",
    "seaborn.clustermap(pyro.param('taxon_sigma').cpu().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f01c405-4e45-41e8-b8ce-578b47e68907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seaborn.clustermap(torch.sigmoid(pyro.param('taxon_particles')).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2972a5-7bbe-466d-8593-e1094bcd9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.store_outputs(device=device,prefix='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3c958-b69f-4b1f-ac3b-c6c45e8f4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmm_heatmaps(antipode_model)\n",
    "plot_d_hists(antipode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a782b8-a259-4f0c-8eba-dc8bd7e8295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDE_KEY = \"X_antipode_MDE\"\n",
    "adata.obsm[MDE_KEY] = scvi.model.utils.mde(adata.obsm['X_antipode'])\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"antipode_cluster\",\"kmeans\"],legend_fontsize=6,legend_fontweight='normal',\n",
    "    legend_loc='on data',palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"species\"],palette=sc.pl.palettes.godsnot_102\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1cd5d-7a88-4052-8ad5-2354b786cc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "random_choice=np.random.choice(adata.obs.index,size=10000,replace=False)\n",
    "random_choice=np.where(adata.obs.index.isin(random_choice))[0]\n",
    "xdata=adata[random_choice,:]\n",
    "xdata=xdata.to_memory().copy()\n",
    "sc.pp.neighbors(xdata,n_neighbors=20, use_rep=\"X_antipode\")\n",
    "sc.tl.umap(xdata)\n",
    "sc.pl.umap(xdata,color=['species'],use_raw=False,legend_loc='on data',palette=sc.pl.palettes.godsnot_102)\n",
    "sc.pl.umap(xdata,color=['psi'],use_raw=False,legend_loc='on data',cmap='coolwarm')\n",
    "sc.pl.umap(xdata,color=['antipode_cluster'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "\"\"\"\n",
    "# xdata.X=xdata.layers['UMIs']\n",
    "# sc.pp.normalize_per_cell(xdata)\n",
    "# sc.pp.log1p(xdata)\n",
    "# sc.pp.scale(xdata,max_value=10)\n",
    "#sc.pl.umap(xdata,color=['GBX2','EOMES','SIX3','OTX2','FOXG1','RBFOX3','TH','PDGFRA','AQP4','FOXJ1','AIF1','TTR','MOG','COL1A2','CD34','COL4A1','NPY','NKX2-1','FOXP2','SATB2','RORB','FEZF2','EMX1'],use_raw=False,cmap='Purples')\n",
    "#sc.pl.umap(xdata,color=['DLX2','PROX1','SCGN','TSHZ1','MEIS2','NKX2-1','LHX6','CRABP1','TSHZ1','FOXG1','PDGFRA','AIF1','AQP4','EDNRB','FOXJ1','CD34','MKI67'],cmap='Purples',use_raw=False)\n",
    "#sc.pl.umap(xdata,color=['RPL7','RPS17','RPL13A','MEF2C'],cmap='Purples',use_raw=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8088c-0ca6-4224-b9c3-5d53125d74bb",
   "metadata": {},
   "source": [
    "# Training Phase 3: Refining the final tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8a556-5e56-4aa0-9c3d-f7514c48e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.train_phase_3(max_steps=max_steps,print_every=10000,num_particles=1,max_learning_rate=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18b1bc-b121-4356-ac48-9775104ab201",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(antipode_model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304689d-821f-4521-b515-414283bef218",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.store_outputs(device=device,prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b70a9-0c3e-4615-ad65-9dd3b6c9b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmm_heatmaps(antipode_model)\n",
    "plot_d_hists(antipode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a8699-4cc3-401f-9d5a-c253b2d4d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.clustermap(torch.sigmoid(pyro.param('taxon_mu')).cpu().detach().numpy())\n",
    "plt.show()\n",
    "seaborn.clustermap(pyro.param('taxon_sigma').cpu().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e5701-b786-4267-bb7b-db00eada2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDE_KEY = \"X_antipode_MDE\"\n",
    "adata.obsm[MDE_KEY] = scvi.model.utils.mde(adata.obsm['X_antipode'])\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"antipode_cluster\",\"kmeans\"],legend_fontsize=6,legend_fontweight='normal',\n",
    "    legend_loc='on data',palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"species\"],palette=sc.pl.palettes.godsnot_102\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3acebd-8220-45de-9581-8ccead8a509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"antipode_cluster\"],\n",
    "    palette=sc.pl.palettes.godsnot_102,\n",
    "    legend_loc='on data'\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"psi\"],\n",
    "    cmap='coolwarm'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733af52-f032-40a4-9f7c-29e232e6f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata.obsm['X_antipode_clipped_MDE']=clip_latent_dimensions(adata.obsm['X_antipode_MDE'],0.1)\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis='X_antipode_clipped_MDE',\n",
    "    color=[\"psi\"],\n",
    "    cmap='coolwarm'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8b601-4c7a-42ff-aa31-509cb4585311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.umap(adata,color=[x for x in adata.obs.columns if 'level' in x]+['antipode_cluster','kmeans'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "\n",
    "random_choice=np.random.choice(adata.obs.index,size=100000,replace=False)\n",
    "random_choice=np.where(adata.obs.index.isin(random_choice))[0]\n",
    "xdata=adata[random_choice,:]\n",
    "xdata=xdata.to_memory().copy()\n",
    "sc.pp.neighbors(xdata,n_neighbors=20, use_rep=\"X_antipode\")\n",
    "sc.tl.umap(xdata)\n",
    "\n",
    "sc.pl.umap(xdata,color=['species'],use_raw=False,palette=sc.pl.palettes.godsnot_102)\n",
    "sc.pl.umap(xdata,color=['psi'],use_raw=False,cmap='coolwarm')\n",
    "sc.pl.umap(xdata,color=['antipode_cluster'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "# xdata.X=xdata.layers['UMIs'].todense()\n",
    "# sc.pp.normalize_per_cell(xdata)\n",
    "# sc.pp.log1p(xdata)\n",
    "# sc.pp.scale(xdata,max_value=10)\n",
    "#sc.pl.umap(xdata,color=gene_list,cmap='Purples',use_raw=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fa96e-bae9-44ce-9c9b-d14f6cea029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata.X=xdata.raw.X.todense()[:,adata.raw.var.index.isin(adata.var.index)]\n",
    "sc.pp.normalize_per_cell(xdata)\n",
    "sc.pp.log1p(xdata)\n",
    "#sc.pp.scale(xdata,max_value=10)\n",
    "\n",
    "gene_list=['RBFOX3','PDGFRA','AQP4','FOXJ1','AIF1','MOG','COL1A2','CD34','COL4A1','SATB2','RORB','DLX2','PROX1','SCGN','TSHZ1','SLC17A7','TLE4','FEZF2',\n",
    "           'MEIS2','NKX2-1','LHX6','CRABP1','TSHZ1','NPY','FOXP1','FOXP2','PDYN','PENK','ISL1','FOXG1','PDGFRA','AIF1','AQP4','EDNRB','FOXJ1','CD34','MKI67','RPL7','RPS17','RPL13A','MEF2C']\n",
    "gene_list=[x for x in gene_list if x in xdata.var.index]\n",
    "sc.pl.embedding(\n",
    "    xdata,\n",
    "    basis=MDE_KEY,\n",
    "    color=gene_list,cmap='Purples',\n",
    "    palette=sc.pl.palettes.godsnot_102,legend_fontsize=6,\n",
    "    legend_loc='on data',use_raw=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934e04e-3306-4e92-973a-c0e496f10cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata.X=xdata.raw.X[:,adata.raw.var.index.isin(adata.var.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1360aa7-5a6e-49ec-9eaf-1ff9b834fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata.write_h5ad('/home/matthew.schmitz/Matthew/1.9.3_stricter.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878318b2-7678-40f2-bfa7-5019db96397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "np.random.seed(0)\n",
    "data = adata.uns['param_store']['discov_di'].var(-1)[:,-antipode_model.level_sizes[-1]:]\n",
    "species = antipode_model.adata_manager.registry['field_registries']['discov_ind']['state_registry']['categorical_mapping']\n",
    "clusters = [f'Cluster_{i}' for i in range(data.shape[-1])]\n",
    "\n",
    "df = pd.DataFrame(data, index=species, columns=clusters)\n",
    "\n",
    "# Annotations for clusters (assuming each cluster has a unique color)\n",
    "cluster_colors = adata.uns['level_3_colors']\n",
    "cluster_lut = dict(zip(map(str, clusters), cluster_colors))\n",
    "cluster_colors = pd.Series(df.columns, index=df.columns).map(cluster_lut)\n",
    "cluster_colors=cluster_colors.fillna('white')\n",
    "\n",
    "# Annotations for predicted subclasses (assuming each subclass has a unique color)\n",
    "# Replace 'subclass_values' with your actual subclass values\n",
    "level_to_subclass=adata.obs.groupby('level_3')['AIT21_subclass'].value_counts().unstack().idxmax(1)\n",
    "level_to_subclass.index=list(level_to_subclass.index.astype(int))\n",
    "for k in range(antipode_model.level_sizes[-1]):\n",
    "    if k not in level_to_subclass.keys():\n",
    "        level_to_subclass[k]='nan'\n",
    "subclasses=[level_to_subclass[k] for k in range(antipode_model.level_sizes[-1])]\n",
    "subclass_colors = [sc.pl.palettes.godsnot_102[x%len(sc.pl.palettes.godsnot_102)] for x in range(len(sc.pl.palettes.godsnot_102))]#sns.color_palette(\"Set2\", len(subclasses))\n",
    "subclass_lut = dict(zip(subclasses, subclass_colors))\n",
    "subclass_lut['nan']='white'\n",
    "subclass_colors = pd.Series(subclasses, index=df.columns).map(subclass_lut)\n",
    "\n",
    "# Concatenate the color annotations into a single DataFrame\n",
    "# Assuming you want these annotations for rows (species)\n",
    "row_colors = pd.DataFrame({'Subclass': subclass_colors,'Cluster': cluster_colors})\n",
    "print(row_colors)\n",
    "\n",
    "# Create the clustermap\n",
    "g = sns.clustermap(df, col_colors=row_colors, figsize=(12, 8))\n",
    "\n",
    "# Create a legend for the colors\n",
    "for label, color in subclass_lut.items():\n",
    "    g.ax_col_dendrogram.bar(0, 0, color=color, label=label, linewidth=0)\n",
    "g.ax_col_dendrogram.legend(title=\"Predicted Subclasses\", loc=\"center\", bbox_to_anchor=(0.5, 1.15), ncol=3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f45daf-83c5-40e4-870a-c933dacfd451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf42a1-16c8-4b4d-87f5-49dfb2a89729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed5c4a-701f-4768-b738-4c5286d1a08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79c3ed-04f1-42d9-8f1b-a986dc7ed412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36573f63-de85-47b2-a0de-c581731381a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb85cef-b77b-4da5-a611-8c22e055e556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
