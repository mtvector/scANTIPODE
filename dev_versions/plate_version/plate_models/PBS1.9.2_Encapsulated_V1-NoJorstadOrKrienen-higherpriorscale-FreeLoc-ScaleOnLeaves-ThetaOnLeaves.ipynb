{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffe491f-acab-469c-90c9-4fb859e695fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/utils/miniconda3/envs/pyro/lib/python3.11/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/utils/miniconda3/envs/pyro/lib/python3.11/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n",
      "/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/utils/miniconda3/envs/pyro/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# various import statements\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import cluster\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import inspect\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus, softmax\n",
    "from torch.distributions import constraints\n",
    "import seaborn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import pyro.optim\n",
    "from pyro.infer import SVI\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "sc.settings.figdir=os.path.expanduser('~/WbFigures/SpeciesDivergenceNoScaling')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a282e6-78c4-4e8a-8ac0-e1db80319c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 464337 × 10019 backed at '/home/matthew.schmitz/Matthew/data/cortex_data/v1_combination_nojo.h5ad'\n",
       "    obs: 'batch', 'species', 'dataset'\n",
       "    var: 'homo_sapiens_symbol', 'tupaia_belangeri_ensemblid', 'rousettus_aegyptiacus_ensemblid', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'featureid', 'highly_variable_features', 'hvf_loess', 'hvf_rank', 'mean', 'n_cells', 'percent_cells', 'robust', 'var', 'gene_name', 'gene', 'Biotype', 'Chromosome', 'End', 'Gene', 'Start', 'Accession'\n",
       "    layers: 'UMIs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata=sc.read_h5ad(os.path.expanduser('/home/matthew.schmitz/Matthew/data/cortex_data/v1_combination_nojo.h5ad'),backed='r')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371c61df-51ad-4d4b-b5b6-39fd5d1e4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/')\n",
    "import antipode_model\n",
    "from antipode_model import *\n",
    "import model_functions\n",
    "from model_functions import *\n",
    "import model_distributions\n",
    "from model_distributions import *\n",
    "import model_modules\n",
    "from model_modules import *\n",
    "import train_utils\n",
    "from train_utils import *\n",
    "import plotting\n",
    "from plotting import *\n",
    "\n",
    "import importlib\n",
    "antipode_model=importlib.reload(antipode_model)\n",
    "from antipode_model import *\n",
    "\n",
    "import importlib\n",
    "model_modules=importlib.reload(model_modules)\n",
    "from model_modules import *\n",
    "\n",
    "model_functions=importlib.reload(model_functions)\n",
    "from model_functions import *\n",
    "\n",
    "import importlib\n",
    "model_distributions=importlib.reload(model_distributions)\n",
    "from model_distributions import *\n",
    "\n",
    "import importlib\n",
    "train_utils=importlib.reload(train_utils)\n",
    "from train_utils import *\n",
    "\n",
    "import importlib\n",
    "plotting=importlib.reload(plotting)\n",
    "from plotting import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2a3ef7d-d676-44ad-b4d4-eade22dfc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntipodeTrainingMixin:\n",
    "    '''\n",
    "    Mixin class providing functions to actually run ANTIPODE\n",
    "    can use supervised taxonomy by training only phase2\n",
    "    '''\n",
    "    \n",
    "    def save_params_to_uns(self,prefix=''):\n",
    "        pstore=param_store_to_numpy()\n",
    "        pstore={n:pstore[n] for n in pstore.keys() if not re.search('encoder|classifier',n)}\n",
    "        self.adata_manager.adata.uns[prefix+'param_store']=pstore\n",
    "\n",
    "    def store_outputs(self,device='cuda',prefix=''):\n",
    "        self.save_params_to_uns(prefix='')\n",
    "        self.to('cpu')\n",
    "        self.eval()\n",
    "        antipode_outs=get_antipode_outputs(self,batch_size=2048,device=device)\n",
    "        taxon=antipode_outs[1][0]\n",
    "        self.adata_manager.adata.obsm['X_antipode']=antipode_outs[0][0]\n",
    "        self.adata_manager.adata.obs['psi']=antipode_outs[1][1]\n",
    "        level_edges=[numpy_hardmax(self.adata_manager.adata.uns['param_store']['edges_'+str(i)],axis=-1) for i in range(len(self.level_sizes)-1)]\n",
    "        levels=self.tree_convergence_bottom_up.just_propagate(scipy.special.softmax(taxon[...,-self.level_sizes[-1]:],axis=-1),level_edges,s=torch.ones(1))\n",
    "        prop_taxon=np.concatenate(levels,axis=-1)\n",
    "        self.adata_manager.adata.obsm['taxon_probs']=prop_taxon\n",
    "        levels=self.tree_convergence_bottom_up.just_propagate(numpy_hardmax(levels[-1],axis=-1),level_edges,s=torch.ones(1))\n",
    "        for i in range(len(levels)):\n",
    "            cur_clust=prefix+'level_'+str(i)\n",
    "            self.adata_manager.adata.obs[cur_clust]=levels[i].argmax(1)\n",
    "            self.adata_manager.adata.obs[cur_clust]=self.adata_manager.adata.obs[cur_clust].astype(str)\n",
    "        self.adata_manager.adata.obs[prefix+'antipode_cluster'] = self.adata_manager.adata.obs.apply(lambda x: '_'.join([x[prefix+'level_'+str(i)] for i in range(len(levels))]), axis=1)\n",
    "    \n",
    "    def train_phase_1(self,max_steps,print_every=10000,device='cuda',max_learning_rate=0.001,num_particles=3,one_cycle_lr=True,steps=0,batch_size=32):\n",
    "        #particle phase\n",
    "        steps=steps\n",
    "        print(self.fields)\n",
    "        print(self.field_types)\n",
    "        dataloader=scvi.dataloaders.AnnDataLoader(self.adata_manager,batch_size=32,drop_last=True,shuffle=True,data_and_attributes=self.field_types)#supervised_field_types for supervised step\n",
    "        scheduler=pyro.optim.OneCycleLR({'max_lr':max_learning_rate,'total_steps':max_steps,'div_factor':100,'optim_args':{},'optimizer':torch.optim.Adam}) if one_cycle_lr else pyro.optim.ClippedAdam({'lr':max_learning_rate,'lrd':(1-(5e-6))})\n",
    "        elbo = pyro.infer.JitTrace_ELBO(num_particles=num_particles,strict_enumeration_warning=False)\n",
    "        svi = SVI(self.model, self.guide, scheduler, elbo)\n",
    "        self.train()\n",
    "        self.zl_encoder.train()\n",
    "        \n",
    "        self=self.to(device)\n",
    "        self.set_approx(True)\n",
    "        loss_tracker=[]\n",
    "        pbar = tqdm.tqdm(total=max_steps, position=0)\n",
    "        done=False\n",
    "        while steps < max_steps:\n",
    "            for x in dataloader:\n",
    "                x['step']=torch.ones(1).to(device)*steps\n",
    "                x=[x[k].to(device) if k in x.keys() else torch.zeros(1) for k in self.args]\n",
    "                loss=svi.step(*x)\n",
    "                steps+=1\n",
    "                if steps<max_steps-1:\n",
    "                    scheduler.step()\n",
    "                else:\n",
    "                    break\n",
    "                pbar.update(1)\n",
    "                loss_tracker.append(loss)\n",
    "                if steps%print_every == 0:\n",
    "                    # Tell the scheduler we've done one epoch.\n",
    "                    pbar.write(\"[Step %02d]  Loss: %.5f\" % (steps, np.mean(loss_tracker[-print_every:])))\n",
    "        \n",
    "        pbar.close()\n",
    "        allDone()\n",
    "        print(\"Finished training!\")\n",
    "        return(loss_tracker)\n",
    "\n",
    "    def prepare_phase_2(self):\n",
    "        '''Run this if not running in supervised only mode (JUST phase2 with provided obsm clustering), runs kmeans, resets tree edges and locs'''\n",
    "        kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=self.level_sizes[-1],init='k-means++',max_iter=1000,reassignment_ratio=0.001,n_init=100,random_state=0).fit(self.adata_manager.adata.obsm['X_antipode'])\n",
    "        self.adata_manager.adata.obs['kmeans']=kmeans.labels_\n",
    "        self.adata_manager.adata.obs['kmeans']=self.adata_manager.adata.obs['kmeans'].astype(str).astype('category')\n",
    "        self.adata_manager.adata.obsm['kmeans_onehot']=numpy_onehot(self.adata_manager.adata.obs['kmeans'].cat.codes,num_classes=self.level_sizes[-1]) #yoh=yoh+1e-10;yoh=oh/oh.sum(-1).reshape(-1,1)#for relaxed\n",
    "        new_locs=torch.concatenate(\n",
    "            [pyro.param('locs').new_zeros(sum(self.level_sizes[:-1]),pyro.param('locs').shape[1]),\n",
    "             torch.tensor(kmeans.cluster_centers_-kmeans.cluster_centers_.mean(0),device=pyro.param('locs').device)],\n",
    "             axis=0)\n",
    "        new_locs[0,:]=torch.tensor(kmeans.cluster_centers_.mean(0))\n",
    "        \n",
    "        pyro.get_param_store().__setitem__('locs',new_locs)\n",
    "        pyro.get_param_store().__setitem__('locs_dynam',new_locs.new_zeros(new_locs.shape))\n",
    "        pyro.get_param_store().__setitem__('scales',self.scale_init_val*new_locs.new_ones(new_locs.shape))\n",
    "        \n",
    "        for n in pyro.get_param_store():\n",
    "            if 'edge' in n:\n",
    "                pyro.get_param_store().__setitem__(n,pyro.param(n).new_zeros(pyro.param(n).shape))\n",
    "        \n",
    "    def train_phase_2(self,max_steps, taxon_label='kmeans_onehot', print_every=10000, device='cuda', max_learning_rate=0.001, num_particles=1, one_cycle_lr=False, steps=0, batch_size=32):\n",
    "        '''empirically works best and fastest with one_cycle_lr=False'''\n",
    "        steps=steps\n",
    "        supervised_field_types=self.field_types.copy()\n",
    "        supervised_fields=self.fields.copy()\n",
    "        supervised_field_types[\"taxon\"]=np.float32\n",
    "        self.adata_manager.register_new_fields([make_field('taxon',('obsm',taxon_label))])\n",
    "        class_dataloader=scvi.dataloaders.AnnDataLoader(self.adata_manager, batch_size=batch_size, drop_last=True, shuffle=True, data_and_attributes=supervised_field_types)\n",
    "        scheduler=pyro.optim.OneCycleLR({'max_lr':max_learning_rate,'total_steps':max_steps, 'div_factor':100,'optim_args':{},'optimizer':torch.optim.Adam}) if one_cycle_lr else pyro.optim.ClippedAdam({'lr':max_learning_rate,'lrd':(1-(5e-6))})\n",
    "        elbo = pyro.infer.JitTrace_ELBO(num_particles=num_particles,strict_enumeration_warning=False)\n",
    "        svi = SVI(self.model, self.guide, scheduler, elbo)\n",
    "        \n",
    "        self.train()\n",
    "        self=self.to(device)\n",
    "        self.set_approx(False)\n",
    "        loss_tracker=[]\n",
    "        #for steps in range(max_steps):\n",
    "        pbar = tqdm.tqdm(total=max_steps, position=0)\n",
    "        done=False\n",
    "        while steps < max_steps:\n",
    "            for x in class_dataloader:\n",
    "                x['step']=torch.ones(1).to(device)*steps\n",
    "                x=[x[k].to(device) if k in x.keys() else torch.zeros(1) for k in self.args]\n",
    "                loss=svi.step(*x)\n",
    "                steps+=1\n",
    "                if steps<=max_steps-1:\n",
    "                    #scheduler.step()\n",
    "                    pass\n",
    "                else:\n",
    "                    break\n",
    "                pbar.update(1)\n",
    "                loss_tracker.append(loss)\n",
    "                if steps%print_every == 0:\n",
    "                    # Tell the scheduler we've done one epoch.\n",
    "                    pbar.write(\"[Step %02d]  Loss: %.5f\" % (steps, np.mean(loss_tracker[-print_every:])))\n",
    "        \n",
    "        pbar.close()\n",
    "        allDone()\n",
    "        print(\"Finished training!\")\n",
    "        return(loss_tracker)\n",
    "        \n",
    "    def train_phase_3(self,max_steps,print_every=10000,device='cuda',max_learning_rate=0.001,num_particles=3,one_cycle_lr=True,steps=0,batch_size=32):\n",
    "        steps=steps\n",
    "        dataloader=scvi.dataloaders.AnnDataLoader(self.adata_manager,batch_size=batch_size,drop_last=True,shuffle=True,data_and_attributes=self.field_types)#supervised_field_types for supervised step\n",
    "        scheduler=pyro.optim.OneCycleLR({'max_lr':max_learning_rate,'total_steps':max_steps,'div_factor':100,'optim_args':{},'optimizer':torch.optim.Adam}) if one_cycle_lr else pyro.optim.ClippedAdam({'lr':max_learning_rate,'lrd':(1-(5e-6))})\n",
    "        elbo = pyro.infer.JitTraceEnum_ELBO(num_particles=num_particles,strict_enumeration_warning=False)\n",
    "        svi = SVI(self.model, self.guide, scheduler, elbo)\n",
    "\n",
    "        loss_tracker=[]\n",
    "        self.train()\n",
    "        self=self.to(device)\n",
    "        self.set_approx(False)\n",
    "        \n",
    "        #for steps in range(max_steps):\n",
    "        pbar = tqdm.tqdm(total=max_steps, position=0)\n",
    "        done=False\n",
    "        while steps < max_steps:\n",
    "            for x in dataloader:\n",
    "                x['step']=torch.ones(1).to(device)*steps\n",
    "                x=[x[k].to(device) if k in x.keys() else torch.zeros(1) for k in self.args]\n",
    "                loss=svi.step(*x)\n",
    "                steps+=1\n",
    "                if steps<max_steps-1:\n",
    "                    #scheduler.step()\n",
    "                    pass\n",
    "                else:\n",
    "                    break\n",
    "                pbar.update(1)\n",
    "                loss_tracker.append(loss)\n",
    "                if steps%print_every == 0:\n",
    "                    # Tell the scheduler we've done one epoch.\n",
    "                    pbar.write(\"[Step %02d]  Loss: %.5f\" % (steps, np.mean(loss_tracker[-print_every:])))\n",
    "        \n",
    "        pbar.close()\n",
    "        allDone()\n",
    "        print(\"Finished training!\")\n",
    "        return(loss_tracker)\n",
    "\n",
    "class ANTIPODE(PyroBaseModuleClass,AntipodeTrainingMixin):#\n",
    "    '''\n",
    "    ANTIPODE (Single Cell Ancestral Node Taxonomy Inference by Parcellation of Differential Expression) \n",
    "    is a variational inference model developed for the simultaneous analysis (DE) and \n",
    "    categorization (taxonomy generation) of cell types across evolution (or now any covariate) using single-cell RNA-seq data.\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): An AnnData object containing the single-cell dataset.\n",
    "    discov_pair (tuple): A tuple indicating the key and location of the discovery covariate \n",
    "                         in the AnnData object. Format: ('key', 'location'), where location is \n",
    "                         either 'obs' or 'obsm'.\n",
    "    batch_pair (tuple): A tuple indicating the key and location of the batch covariate \n",
    "                        in the AnnData object. Format: ('key', 'location'), where location is \n",
    "                        either 'obs' or 'obsm'.\n",
    "    num_var (int): Number of variables (features) in the dataset.\n",
    "    level_sizes (list of int, optional): Sizes of each level in the model's hierarchical structure. \n",
    "                                         Defaults to [1, 10, 25, 50].\n",
    "    num_latent (int, optional): Number of latent dimensions. Defaults to 50.\n",
    "    scale_factor (float, optional): Scaling factor for data normalization. If None, it is inferred from the data.\n",
    "    prior_scale (float, optional): Scale of the Laplace prior distributions. Defaults to 100.\n",
    "    dcd_prior (float, optional): Scale of the prior for the decoder. If None, defaults to a specific inferred value.\n",
    "    theta_prior (float, optional): Init value for the inverse dispersion of the negative binomial.\n",
    "    decay_function (callable, optional): A function that defines the decay of certain parameters over iterations.\n",
    "    max_strictness (float, optional): Maximum strictness parameter for tree convergence. Defaults to 1.\n",
    "    bi_depth (int, optional): Depth of the tree for the approximation of batch by identity effects. Defaults to 2.\n",
    "    num_batch_embed (int, optional): Number of batch embeddings. Defaults to 10.\n",
    "    classifier_hidden (list of int, optional): Sizes of hidden layers for the classifier network. Defaults to [3000, 3000, 3000].\n",
    "    encoder_hidden (list of int, optional): Sizes of hidden layers for the encoder network. Defaults to [6000, 5000, 3000, 1000].\n",
    "    '''\n",
    "    def __init__(self, adata, discov_pair, batch_pair, layer, level_sizes=[1, 10, 25, 50], \n",
    "                 num_latent=50, scale_factor=None, prior_scale=100,dcd_prior=None,use_psi=True,loc_as_param=False,zdw_as_param=False,\n",
    "                 decay_function=None, max_strictness=1., bi_depth=2, num_batch_embed=10,theta_prior=50.,scale_init_val=0.01,\n",
    "                 classifier_hidden=[3000,3000,3000],encoder_hidden=[6000,5000,3000,1000],phase1_treeest=False,z_transform=None):\n",
    "\n",
    "        pyro.clear_param_store()\n",
    "\n",
    "        # Determine num_discov and num_batch from the AnnData object\n",
    "        self.discov_loc, self.discov_key = discov_pair\n",
    "        self.batch_loc, self.batch_key = batch_pair\n",
    "        self.num_discov = adata.obsm[self.discov_key].shape[-1] if self.discov_loc == 'obsm' else len(adata.obs[self.discov_key].unique())\n",
    "        self.num_batch = adata.obsm[self.batch_key].shape[-1] if self.batch_loc == 'obsm' else len(adata.obs[self.batch_key].unique())\n",
    "        self.design_matrix = (self.discov_loc == 'obsm')\n",
    "        self.layer=layer\n",
    "\n",
    "        self._setup_adata_manager_store: dict[str, type[scvi.data.AnnDataManager]] = {}\n",
    "        self.num_var = adata.layers[layer].shape[-1]\n",
    "        self.num_latent = num_latent\n",
    "        self.scale_factor = scale_factor if scale_factor is not None else 2e2 / (self.num_var * num_labels * num_latent)\n",
    "        self.level_sizes = level_sizes\n",
    "        self.num_labels = np.sum(self.level_sizes)\n",
    "        self.level_indices = np.cumsum([0] + self.level_sizes)\n",
    "        self.bi_depth = bi_depth\n",
    "        self.num_bi_depth = sum(self.level_sizes[:self.bi_depth])\n",
    "        self.num_batch_embed = num_batch_embed\n",
    "        self.max_strictness = 1.\n",
    "        self.decay_function = gen_linear_function(2,1) if decay_function is None else decay_function \n",
    "        self.temperature = 0.1\n",
    "        self.epsilon = 0.006\n",
    "        self.approx = False\n",
    "        self.prior_scale = prior_scale\n",
    "        self.use_psi=use_psi\n",
    "        self.loc_as_param=loc_as_param\n",
    "        self.zdw_as_param=zdw_as_param\n",
    "        self.theta_prior=theta_prior\n",
    "        self.phase1_treeest=phase1_treeest\n",
    "        self.scale_init_val=scale_init_val\n",
    "        self.leaf_scale_only=False\n",
    "        \n",
    "        self.dcd_prior=torch.zeros((self.num_discov,self.num_var)) if dcd_prior is None else dcd_prior#Use this for \n",
    "        \n",
    "        # Initialize plates to be used during sampling\n",
    "        self.var_plate=pyro.plate('var_plate',self.num_var,dim=-1)\n",
    "        self.discov_plate=pyro.plate('discov_plate',self.num_discov,dim=-3)\n",
    "        self.batch_plate=pyro.plate('batch_plate',self.num_batch,dim=-3)\n",
    "        self.latent_plate=pyro.plate('latent_plate',self.num_latent,dim=-1)\n",
    "        self.latent_plate2=pyro.plate('latent_plate2',self.num_latent,dim=-2)\n",
    "        self.label_plate=pyro.plate('label_plate',self.num_labels,dim=-2)\n",
    "        self.batch_embed_plate=pyro.plate('batch_embed_plate',self.num_batch_embed,dim=-3)\n",
    "        self.bi_depth_plate=pyro.plate('bi_depth_plate',self.num_bi_depth,dim=-2)\n",
    "\n",
    "        #Initialize MAP inference modules\n",
    "        self.dm=MAPLaplaceModule(self,'discov_dm',[self.num_discov,self.num_labels,self.num_latent],[self.discov_plate,self.label_plate,self.latent_plate])\n",
    "        self.bm=MAPLaplaceModule(self,'batch_dm',[self.num_batch,self.num_labels,self.num_latent],[self.batch_plate,self.label_plate,self.latent_plate])\n",
    "        self.di=MAPLaplaceModule(self,'discov_di',[self.num_discov,self.num_labels,self.num_var],[self.discov_plate,self.label_plate,self.var_plate])\n",
    "        self.bei=MAPLaplaceModule(self,'batch_di',[self.num_batch_embed,self.num_bi_depth,self.num_var],[self.batch_embed_plate,self.bi_depth_plate,self.var_plate])\n",
    "        self.ci=MAPLaplaceModule(self,'cluster_intercept',[self.num_labels, self.num_var],[self.label_plate,self.var_plate])\n",
    "        self.dc=MAPLaplaceModule(self,'discov_dc',[self.num_discov,self.num_latent,self.num_var],[self.discov_plate,self.latent_plate2,self.var_plate])\n",
    "        self.zdw=MAPLaplaceModule(self,'z_decoder_weight',[self.num_latent,self.num_var],[self.latent_plate2,self.var_plate],init_val=((2/self.num_latent)*(torch.rand(self.num_latent,self.num_var)-0.5)),param_only=self.zdw_as_param)\n",
    "        self.zl=MAPLaplaceModule(self,'locs',[self.num_labels,self.num_latent],[self.label_plate,self.latent_plate],param_only=self.loc_as_param)\n",
    "        self.zs=MAPLaplaceModule(self,'scales',[self.num_labels,self.num_latent],[self.label_plate,self.latent_plate],init_val=self.scale_init_val*torch.ones(self.num_labels,self.num_latent),constraint=constraints.positive,param_only=False)\n",
    "        self.zld=MAPLaplaceModule(self,'locs_dynam',[self.num_labels,self.num_latent],[self.label_plate,self.latent_plate],param_only=False)\n",
    "        \n",
    "        self.tree_edges=TreeEdges(self,straight_through=True)\n",
    "        self.tree_convergence=TreeConvergence(self,strictness=1.)        \n",
    "        self.tree_convergence_bottom_up=TreeConvergenceBottomUp(self,strictness=1.)        \n",
    "        self.z_transform=null_function if z_transform is None else z_transform#centered_sigmoid#torch.special.expit\n",
    "\n",
    "        if self.design_matrix:\n",
    "            fields={'s':('layers',self.layer),\n",
    "            'discov_ind':('obsm',self.discov_key),\n",
    "            'batch_ind':('obsm',self.batch_key)}\n",
    "            field_types={\"s\":np.float32,\"batch_ind\":np.float32,\"discov_ind\":np.float32}\n",
    "        else:\n",
    "            fields={'s':('layers',self.layer),\n",
    "            'discov_ind':('obs',self.discov_key),\n",
    "            'batch_ind':('obs',self.batch_key)}\n",
    "            field_types={\"s\":np.float32,\"batch_ind\":np.int64,\"discov_ind\":np.int64}\n",
    "\n",
    "        self.fields=fields\n",
    "        self.field_types=field_types\n",
    "        self.setup_anndata(adata, {'discov_ind': discov_pair, 'batch_ind': batch_pair}, self.field_types)\n",
    "        \n",
    "        super().__init__()\n",
    "        # Setup the various neural networks used in the model and guide\n",
    "        self.z_decoder=ZDecoder(num_latent=self.num_latent, num_var=self.num_var, hidden_dims=[])        \n",
    "        self.zl_encoder=ZLEncoder(num_var=self.num_var,hidden_dims=encoder_hidden,num_cat_input=self.num_discov,\n",
    "                    outputs=[(self.num_latent,None),(self.num_latent,softplus)])\n",
    "        \n",
    "        self.classifier=Classifier(num_latent=self.num_latent,hidden_dims=classifier_hidden,\n",
    "                    outputs=[(self.num_labels,None),(1,None),(1,softplus)])\n",
    "\n",
    "        #self.bc_nn=SimpleFFNN(in_dim=self.num_batch,hidden_dims=[200,200,50,5],\n",
    "        #            out_dim=self.num_var*self.num_latent)\n",
    "        #Too large to exactly model gene-level batch effects for all cluster x batch\n",
    "        self.be_nn=SimpleFFNN(in_dim=self.num_batch,hidden_dims=[1000,500,500],\n",
    "                    out_dim=self.num_batch_embed)\n",
    "        \n",
    "        self.epsilon = 0.006\n",
    "        #Initialize model in approximation mode\n",
    "        self.approx=False\n",
    "        self.prior_scale=prior_scale\n",
    "        self.args=inspect.getfullargspec(self.model).args[1:]#skip self\n",
    "\n",
    "    def setup_anndata(self,adata: anndata.AnnData,fields,field_types,**kwargs,):\n",
    "        \n",
    "        anndata_fields=[make_field(x,self.fields[x]) for x in self.fields.keys()]\n",
    "        \n",
    "        adata_manager = scvi.data.AnnDataManager(\n",
    "            fields=anndata_fields\n",
    "        )\n",
    "        adata_manager.register_fields(adata, **kwargs)\n",
    "        self.register_manager(adata_manager)\n",
    "        if fields['discov_ind'][0]=='obsm':\n",
    "            self.design_matrix=True\n",
    "            if fields['batch_ind'][0]!='obsm':\n",
    "                raise Exception(\"If discov is design matrix, batch must be as well!\")\n",
    "\n",
    "\n",
    "    def register_manager(self, adata_manager: scvi.data.AnnDataManager):\n",
    "        adata_id = adata_manager.adata_uuid\n",
    "        self._setup_adata_manager_store[adata_id] = adata_manager\n",
    "        self.adata_manager=adata_manager\n",
    "    \n",
    "    def set_approx(self,b: bool):\n",
    "        self.approx=b\n",
    "    \n",
    "    def set_leaf_scale_only(self,b: bool):\n",
    "        self.leaf_scale_only=b\n",
    "        \n",
    "    def model(self, s,discov_ind=torch.zeros(1),batch_ind=torch.zeros(1),step=torch.ones(1),taxon=torch.zeros(1)):\n",
    "        # Register various nn.Modules (i.e. the decoder/encoder networks) with Pyro\n",
    "        pyro.module(\"antipode\", self)\n",
    "\n",
    "        if not self.design_matrix:\n",
    "            batch=index_to_onehot(batch_ind,[s.shape[0],self.num_batch]).to(s.device)\n",
    "            discov=index_to_onehot(discov_ind,[s.shape[0],self.num_discov]).to(s.device)\n",
    "            batch_ind=batch_ind.squeeze()\n",
    "            discov_ind=discov_ind.squeeze()\n",
    "        else:\n",
    "            batch=batch_ind\n",
    "            discov=discov_ind\n",
    "        \n",
    "        minibatch_plate=pyro.plate(\"minibatch_plate\", s.shape[0],dim=-1)\n",
    "        minibatch_plate2=pyro.plate(\"minibatch_plate2\", s.shape[0],dim=-2)\n",
    "        cur_strictness=self.decay_function(step, self.max_strictness)\n",
    "        l = s.sum(1).unsqueeze(-1)\n",
    "        \n",
    "        # We scale all sample statements by scale_factor so that the ELBO loss function\n",
    "        # is normalized wrt the number of datapoints and genes.\n",
    "        # This helps with numerical stability during optimization.\n",
    "        with poutine.scale(scale=self.scale_factor):\n",
    "            # This gene-level parameter modulates the variance of the observation distribution\n",
    "            s_theta = pyro.param(\"s_inverse_dispersion\", self.theta_prior * s.new_ones(self.level_sizes[-1],self.num_var),\n",
    "                               constraint=constraints.positive)\n",
    "            \n",
    "            dcd=pyro.param(\"discov_constitutive_de\", self.dcd_prior.to(s.device))\n",
    "            level_edges=self.tree_edges.model_sample(s,approx=self.approx)\n",
    "            \n",
    "            with minibatch_plate:\n",
    "                beta_prior_a=1.*s.new_ones(self.num_labels)\n",
    "                beta_prior_a[0]=10.\n",
    "                if self.approx:#Bernoulli particles approx?\n",
    "                    taxon_probs = pyro.sample(\"taxon_probs\", dist.Beta(beta_prior_a,s.new_ones(self.num_labels),validate_args=True).to_event(1))\n",
    "                    taxon = pyro.sample('taxon',dist.RelaxedBernoulli(temperature=0.1*s.new_ones(1),probs=taxon_probs).to_event(1))\n",
    "                    if self.phase1_treeest:\n",
    "                        self.tree_convergence.model_sample(taxon,level_edges,s,cur_strictness)#Someday will be possible to properly generate Undirected acyclic graphs here\n",
    "                else:\n",
    "                    taxon_probs=pyro.sample('taxon_probs',dist.Dirichlet(s.new_ones(s.shape[0],self.level_sizes[-1]),validate_args=True))\n",
    "                    if sum(taxon.shape) > 1:#Supervised?\n",
    "                        if taxon.shape[-1]==self.num_labels:#Totally supervised?\n",
    "                            pass\n",
    "                        else:#Only bottom layer is supervised?\n",
    "                            taxon = pyro.sample(\"taxon\", dist.OneHotCategorical(probs=taxon_probs,validate_args=True),obs=taxon)\n",
    "                            taxon = torch.concat(self.tree_convergence_bottom_up.just_propagate(taxon,level_edges,s),-1)\n",
    "                    else:#Unsupervised\n",
    "                        taxon = pyro.sample(\"taxon\", dist.OneHotCategorical(probs=taxon_probs,validate_args=True),infer={'enumerate':'parallel'})\n",
    "                        taxon = torch.concat(self.tree_convergence_bottom_up.just_propagate(taxon,level_edges,s),-1)\n",
    "                    taxon_probs=self.tree_convergence_bottom_up.just_propagate(taxon_probs,level_edges,s,cur_strictness)\n",
    "                    taxon_probs=torch.cat(taxon_probs,-1)\n",
    "                   \n",
    "            locs=self.zl.model_sample(s,scale=fest([taxon_probs],-1))\n",
    "            scales=self.zs.model_sample(s,scale=fest([taxon_probs],-1))\n",
    "            locs_dynam=self.zld.model_sample(s,scale=fest([taxon_probs],-1))\n",
    "            discov_dm=self.dm.model_sample(s,scale=fest([discov,taxon_probs],-1))\n",
    "            discov_di=self.di.model_sample(s,scale=fest([discov,taxon_probs],-1))\n",
    "            batch_dm=self.bm.model_sample(s,scale=fest([batch,taxon_probs],-1))\n",
    "            batch_embed=centered_sigmoid(self.be_nn(batch))\n",
    "            bei=self.bei.model_sample(s,scale=fest([batch_embed,taxon_probs[...,:self.num_bi_depth]],-1))\n",
    "            cluster_intercept=self.ci.model_sample(s,scale=fest([taxon_probs],-1))\n",
    "            \n",
    "            with minibatch_plate:\n",
    "                bi=torch.einsum('...bi,...ijk->...bjk',batch_embed,bei)\n",
    "                bi=torch.einsum('...bj,...bjk->...bk',taxon[...,:self.num_bi_depth],bi)\n",
    "                psi = centered_sigmoid(pyro.sample('psi',dist.Laplace(s.new_zeros(s.shape[0],1),self.prior_scale*s.new_ones(s.shape[0],1)).to_event(1)))\n",
    "                psi = 0 if not self.use_psi else psi\n",
    "                this_locs=oh_index(locs,taxon)\n",
    "                this_scales=oh_index(scales[-self.level_sizes[-1]:,:],taxon[...,-self.level_sizes[-1]:]) if self.leaf_scale_only else oh_index(scales,taxon)\n",
    "                z=pyro.sample('z', dist.Normal(this_locs,this_scales+self.epsilon,validate_args=True).to_event(1))\n",
    "\n",
    "            cur_discov_dm = oh_index1(discov_dm, discov_ind) if self.design_matrix else discov_dm[discov_ind]\n",
    "            cur_batch_dm = oh_index1(batch_dm, batch_ind) if self.design_matrix else batch_dm[batch_ind]\n",
    "            cur_dcd = oh_index(dcd, discov) if self.design_matrix else  dcd[discov_ind]\n",
    "            \n",
    "            z=z+oh_index2(cur_discov_dm,taxon) + oh_index2(cur_batch_dm,taxon)+(oh_index(locs_dynam,taxon)*psi)\n",
    "            z=self.z_transform(z)                \n",
    "            fake_z=oh_index(locs,taxon_probs)+oh_index2(discov_dm[discov_ind],taxon_probs) + oh_index2(batch_dm[batch_ind],taxon_probs)+(oh_index(locs_dynam,taxon_probs)*psi)\n",
    "            fake_z=self.z_transform(fake_z)\n",
    "            z_decoder_weight=self.zdw.model_sample(s,scale=fest([fake_z.abs()],-1))\n",
    "            discov_dc=self.dc.model_sample(s,scale=fest([discov,fake_z.abs()],-1))\n",
    "            cur_discov_di = oh_index1(discov_di, discov_ind) if self.design_matrix else discov_di[discov_ind]\n",
    "            cur_discov_dc = oh_index1(discov_dc, discov_ind) if self.design_matrix else discov_dc[discov_ind]\n",
    "            cur_discov_di=oh_index2(cur_discov_di,taxon)\n",
    "            cur_cluster_intercept=oh_index(cluster_intercept,taxon)\n",
    "            \n",
    "            mu=torch.einsum('...bi,...bij->...bj',z,z_decoder_weight+cur_discov_dc)#+bc\n",
    "            spliced_mu=mu+cur_dcd+cur_discov_di+cur_cluster_intercept+bi\n",
    "            spliced_out=torch.softmax(spliced_mu,dim=-1)\n",
    "            log_mu = (l * spliced_out + 1e-6).log()\n",
    "            print(s_theta.is_leaf)\n",
    "            print(taxon[...,-self.level_sizes[-1]:].is_leaf)\n",
    "            this_theta=oh_index(s_theta,taxon[...,-self.level_sizes[-1]:])\n",
    "            print(this_theta.is_leaf)\n",
    "            print(log_mu.is_leaf)\n",
    "            with self.var_plate,minibatch_plate2:\n",
    "                s_dist = dist.NegativeBinomial(total_count=this_theta,logits=log_mu-this_theta.log(),validate_args=True)\n",
    "                s_out=pyro.sample(\"s\", s_dist, obs=s.int())\n",
    "\n",
    "    \n",
    "    # The guide specifies the variational distribution\n",
    "    def guide(self, s,discov_ind=torch.zeros(1),batch_ind=torch.zeros(1),step=torch.ones(1),taxon=torch.zeros(1)):\n",
    "        pyro.module(\"antipode\", self)\n",
    "        \n",
    "        if not self.design_matrix:\n",
    "            batch=index_to_onehot(batch_ind,[s.shape[0],self.num_batch]).to(s.device)\n",
    "            discov=index_to_onehot(discov_ind,[s.shape[0],self.num_discov]).to(s.device)\n",
    "            batch_ind=batch_ind.squeeze()\n",
    "            discov_ind=discov_ind.squeeze()\n",
    "        else:\n",
    "            batch=batch_ind\n",
    "            discov=discov_ind\n",
    "        \n",
    "        minibatch_plate=pyro.plate(\"minibatch_plate\", s.shape[0])\n",
    "        cur_strictness=self.decay_function(step, self.max_strictness)\n",
    "        \n",
    "        with poutine.scale(scale=self.scale_factor):\n",
    "            level_edges=self.tree_edges.guide_sample(s,approx=self.approx) \n",
    "            with minibatch_plate:\n",
    "                z_loc, z_scale= self.zl_encoder(s,discov)\n",
    "                z=pyro.sample('z',dist.Normal(z_loc,z_scale+self.epsilon).to_event(1))\n",
    "                z=self.z_transform(z)\n",
    "                taxon_logits,psi_loc,psi_scale=self.classifier(z)\n",
    "                psi=centered_sigmoid(pyro.sample('psi',dist.Normal(psi_loc,psi_scale).to_event(1)))\n",
    "                psi = 0 if not self.use_psi else psi\n",
    "                if self.approx:\n",
    "                    taxon_dist = dist.Delta(safe_sigmoid(taxon_logits),validate_args=True).to_event(1)\n",
    "                    taxon_probs = pyro.sample(\"taxon_probs\", taxon_dist)\n",
    "                    taxon = pyro.sample('taxon',dist.RelaxedBernoulli(temperature=self.temperature*s.new_ones(1),probs=taxon_probs).to_event(1))\n",
    "                    if self.phase1_treeest:\n",
    "                        self.tree_convergence.guide_sample(taxon,level_edges,s,cur_strictness)\n",
    "                else:\n",
    "                    taxon_probs=pyro.sample('taxon_probs',dist.Delta(safe_softmax(taxon_logits[...,-self.level_sizes[-1]:])).to_event(1))\n",
    "                    if sum(taxon.shape) > 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        taxon = pyro.sample(\"taxon\", \n",
    "                                         dist.OneHotCategorical(probs=taxon_probs,validate_args=True),infer={'enumerate':'parallel'})                    \n",
    "                    if taxon.shape[-1]<self.num_labels:\n",
    "                        taxon = torch.concat(self.tree_convergence_bottom_up.just_propagate(taxon,level_edges,s),-1)\n",
    "\n",
    "                    taxon_probs=self.tree_convergence_bottom_up.just_propagate(taxon_probs[...,-self.level_sizes[-1]:],level_edges,s,cur_strictness)\n",
    "                    taxon_probs=torch.cat(taxon_probs,-1)\n",
    "            locs=self.zl.guide_sample(s,scale=fest([taxon_probs],-1))\n",
    "            scales=self.zs.guide_sample(s,scale=fest([taxon_probs],-1))\n",
    "            locs_dynam=self.zld.guide_sample(s,scale=fest([taxon_probs],-1))\n",
    "            discov_dm=self.dm.guide_sample(s,scale=fest([discov,taxon_probs],-1))\n",
    "            batch_dm=self.bm.guide_sample(s,scale=fest([batch,taxon_probs],-1))\n",
    "            batch_embed=centered_sigmoid(self.be_nn(batch))\n",
    "            discov_di=self.di.guide_sample(s,scale=fest([discov,taxon_probs],-1))\n",
    "            cluster_intercept=self.ci.guide_sample(s,scale=fest([taxon_probs],-1))\n",
    "            bei=self.bei.guide_sample(s,scale=fest([batch_embed,taxon_probs[...,:self.num_bi_depth]],-1))#maybe should be abs sum bei\n",
    "            if self.design_matrix:\n",
    "                z=z+oh_index2(oh_index1(discov_dm,discov_ind),taxon) + oh_index2(oh_index1(batch_dm,batch_ind),taxon)+(oh_index(locs_dynam,taxon)*psi)\n",
    "            else:\n",
    "                z=z+oh_index2(discov_dm[discov_ind],taxon) + oh_index2(batch_dm[batch_ind],taxon)+(oh_index(locs_dynam,taxon)*psi)\n",
    "            z=self.z_transform(z)\n",
    "            fake_z=oh_index(locs,taxon_probs)+oh_index2(discov_dm[discov_ind],taxon_probs) + oh_index2(batch_dm[batch_ind],taxon_probs)+(oh_index(locs_dynam,taxon_probs)*psi)\n",
    "            fake_z=self.z_transform(fake_z)\n",
    "            z_decoder_weight=self.zdw.guide_sample(s,scale=fest([fake_z.abs()],-1))\n",
    "            discov_dc=self.dc.guide_sample(s,scale=fest([discov,fake_z.abs()],-1))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b55ede1a-5159-40ae-bb51-f03a129f7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata=sc.read_h5ad(os.path.expanduser('/home/matthew.schmitz/Matthew/data/cortex_data/v1_combination.h5ad'),backed='r')\n",
    "# adata=adata[~adata.obs['dataset'].isin(['jorstad_cross_areal','krienen_marmoset']),:]\n",
    "# adata.write_h5ad(os.path.expanduser('/home/matthew.schmitz/Matthew/data/cortex_data/v1_combination_nojo.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c21afa78-5434-4993-9d2b-6ee84218dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['species_colors']=['blue','red','green','yellow','orange','pink','turquoise','magenta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8188b4f-93d3-417e-b6d6-061bdb88f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pyro.clear_param_store()\n",
    "    del antipode_model\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa3438c5-dd7e-41aa-bde8-2183986f0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_var=adata.shape[1]\n",
    "batch_size=32\n",
    "level_sizes=[1,10,30,125,250]\n",
    "num_latent=200\n",
    "num_labels=sum(level_sizes)\n",
    "steps=0\n",
    "max_steps=50000\n",
    "print_every=5000\n",
    "\n",
    "# Clear Pyro param store so we don't conflict with previous run\n",
    "pyro.clear_param_store()\n",
    "# Fix random number seed to a lucky number\n",
    "pyro.util.set_rng_seed(13)\n",
    "# Enable optional validation warnings\n",
    "pyro.enable_validation(False)\n",
    "\n",
    "decay_function=gen_linear_function(max_steps,10000)#gen_exponential_decay(5e-6)\n",
    "\n",
    "# Instantiate instance of model/guide and various neural networks\n",
    "antipode_model = ANTIPODE(num_latent=num_latent,level_sizes=level_sizes,\n",
    "                adata=adata,discov_pair=('obs','species'),batch_pair=('obs','batch'),layer='UMIs',loc_as_param=True,\n",
    "                scale_factor=1e2 / (3*batch_size * num_var * num_labels * num_latent),scale_init_val=0.01,\n",
    "                bi_depth=2,decay_function=decay_function,max_strictness=100,prior_scale=10000.,num_batch_embed=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181029a-beb4-4d05-bdda-3854b8fda660",
   "metadata": {},
   "source": [
    "# Training Phase 1: Particlized tree approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7d7be17-ca10-42bd-9b6a-deacd43f59aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': ('layers', 'UMIs'), 'discov_ind': ('obs', 'species'), 'batch_ind': ('obs', 'batch')}\n",
      "{'s': <class 'numpy.float32'>, 'batch_ind': <class 'numpy.int64'>, 'discov_ind': <class 'numpy.int64'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[1.2506e-04, 1.8694e-21, 6.8889e-01,  ..., 1.1208e-01, 8.6607e-01,\n",
      "         9.9808e-01],\n",
      "        [5.7411e-01, 4.7448e-03, 1.0000e+00,  ..., 4.4948e-01, 2.2104e-01,\n",
      "         9.9999e-01],\n",
      "        [2.8984e-02, 5.4585e-10, 1.2018e-05,  ..., 1.0000e+00, 6.4540e-08,\n",
      "         9.9999e-01],\n",
      "        ...,\n",
      "        [2.0473e-15, 1.7438e-01, 1.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         3.3857e-12],\n",
      "        [6.2406e-01, 1.0000e+00, 9.2941e-09,  ..., 8.2472e-01, 9.1508e-01,\n",
      "         9.9990e-01],\n",
      "        [1.1397e-12, 2.0171e-19, 2.2743e-04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         3.4821e-11]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[ 1.2253,  1.0322,  1.2323,  ...,  1.1592,  1.2992,  1.1869],\n",
      "        [-3.3253, -3.2687, -3.3509,  ..., -3.4062, -3.2937, -3.2955],\n",
      "        [-0.9435, -0.9729, -0.9928,  ..., -1.0162, -1.0279, -0.9923],\n",
      "        ...,\n",
      "        [-0.1397, -0.1442, -0.0686,  ..., -0.0263, -0.0208, -0.2118],\n",
      "        [-0.7258, -0.6703, -0.7285,  ..., -0.6583, -0.7597, -0.7599],\n",
      "        [-2.3539, -2.2844, -2.3310,  ..., -2.2915, -2.2234, -2.3210]],\n",
      "       device='cuda:0', grad_fn=<LogBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/model_functions.py:218: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sum(index.shape) == 1:\n",
      "/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/model_functions.py:221: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  index=torch.nn.functional.one_hot(index.squeeze(),num_classes=out_shape[1]).float() if index.shape[-1]==1 else index\n",
      "/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/model_functions.py:254: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x < start_point:\n",
      "/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/model_functions.py:218: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sum(index.shape) == 1:\n",
      "/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/model_functions.py:221: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  index=torch.nn.functional.one_hot(index.squeeze(),num_classes=out_shape[1]).float() if index.shape[-1]==1 else index\n",
      "/home/matthew.schmitz/Matthew/code/scANTIPODE/antipode/model_functions.py:254: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x < start_point:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[1.0000e+00, 1.0000e+00, 1.3910e-04,  ..., 9.9400e-01, 1.4048e-13,\n",
      "         1.0000e+00],\n",
      "        [1.7524e-03, 1.4976e-01, 4.5200e-09,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0199e-03],\n",
      "        [1.0000e+00, 9.9883e-01, 1.3958e-14,  ..., 1.0696e-05, 1.0000e+00,\n",
      "         9.9989e-01],\n",
      "        ...,\n",
      "        [4.4461e-17, 9.9999e-01, 8.0063e-13,  ..., 5.1456e-06, 9.9484e-01,\n",
      "         1.0000e+00],\n",
      "        [1.0000e+00, 2.0277e-04, 9.9637e-01,  ..., 1.0232e-06, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [1.0000e+00, 1.0151e-08, 1.7353e-10,  ..., 1.4947e-02, 2.8958e-12,\n",
      "         9.9963e-01]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[ 1.2336,  1.1868,  1.1783,  ...,  1.2806,  1.1195,  1.1011],\n",
      "        [-3.3470, -3.3078, -3.4110,  ..., -3.3975, -3.3737, -3.2801],\n",
      "        [-0.9380, -0.9496, -1.0059,  ..., -0.9454, -1.0038, -0.8616],\n",
      "        ...,\n",
      "        [-0.0685, -0.0039, -0.0487,  ...,  0.0249, -0.0346, -0.1374],\n",
      "        [-0.7562, -0.7386, -0.7941,  ..., -0.7023, -0.7639, -0.6792],\n",
      "        [-2.3062, -2.3032, -2.2976,  ..., -2.3011, -2.2289, -2.2821]],\n",
      "       device='cuda:0', grad_fn=<LogBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5583/50000 [04:13<29:25, 25.16it/s] \n",
      "KeyboardInterrupt\n",
      "\n",
      "  0%|          | 2/50000 [30:56<12893:18:11, 928.35s/it]\n",
      "  0%|          | 2/50000 [29:04<12116:18:28, 872.41s/it]\n",
      "  0%|          | 2/50000 [28:23<11832:29:48, 851.97s/it]\n",
      "  0%|          | 0/50000 [27:40<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "antipode_model.train_phase_1(max_steps=max_steps,print_every=10000,num_particles=1)\n",
    "antipode_model.store_outputs(device=device,prefix='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250db4c-2c28-4fcd-bcdb-059d8810cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmm_heatmaps(antipode_model)\n",
    "plot_tree_edge_weights(antipode_model)\n",
    "plot_d_hists(antipode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce8d82-5d92-4eb7-9abd-12c47f1379f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDE_KEY = \"X_antipode_MDE\"\n",
    "adata.obsm[MDE_KEY] = scvi.model.utils.mde(adata.obsm['X_antipode'])\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"antipode_cluster\"],legend_fontsize=6,legend_fontweight='normal',\n",
    "    legend_loc='on data',palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"species\"],palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=['dataset'],palette=sc.pl.palettes.godsnot_102\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de70cb5-08f1-4fc1-86ac-dc777e7615b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.umap(adata,color=[x for x in adata.obs.columns if 'level' in x]+['antipode_cluster'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "random_choice=np.random.choice(adata.obs.index,size=20000,replace=False)\n",
    "random_choice=np.where(adata.obs.index.isin(random_choice))[0]\n",
    "xdata=adata[random_choice,:]\n",
    "xdata=xdata.to_memory().copy()\n",
    "sc.pp.neighbors(xdata,n_neighbors=20, use_rep=\"X_antipode\")\n",
    "sc.tl.umap(xdata)\n",
    "sc.pl.umap(xdata,color=['species','dataset'],use_raw=False,palette=sc.pl.palettes.godsnot_102)\n",
    "sc.pl.umap(xdata,color=['psi'],use_raw=False,legend_loc='on data',cmap='coolwarm')\n",
    "sc.pl.umap(xdata,color=[x for x in adata.obs.columns if 'level' in x]+['antipode_cluster'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "# xdata.X=xdata.layers['UMIs']\n",
    "# sc.pp.normalize_per_cell(xdata)\n",
    "# sc.pp.log1p(xdata)\n",
    "# sc.pp.scale(xdata,max_value=10)\n",
    "#sc.pl.umap(xdata,color=['GBX2','EOMES','SIX3','OTX2','FOXG1','RBFOX3','TH','PDGFRA','AQP4','FOXJ1','AIF1','TTR','MOG','COL1A2','CD34','COL4A1','NPY','NKX2-1','FOXP2','SATB2','RORB','FEZF2','EMX1'],use_raw=False,cmap='Purples')\n",
    "#sc.pl.umap(xdata,color=['DLX2','PROX1','SCGN','TSHZ1','MEIS2','NKX2-1','LHX6','CRABP1','TSHZ1','FOXG1','PDGFRA','AIF1','AQP4','EDNRB','FOXJ1','CD34','MKI67'],cmap='Purples',use_raw=False)\n",
    "#sc.pl.umap(xdata,color=['RPL7','RPS17','RPL13A','MEF2C'],cmap='Purples',use_raw=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4ded4-2f42-456e-bbc8-9d5c0d2b178b",
   "metadata": {},
   "source": [
    "# Training Phase 2: Inintializing categorical layered tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051283f-c330-439d-95f5-ad7ae9c9d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.set_leaf_scale_only(True)\n",
    "antipode_model.prepare_phase_2()\n",
    "#sc.pl.umap(adata,color=['kmeans'],legend_loc=\"on data\",palette=sc.pl.palettes.godsnot_102)\n",
    "adata.obs['kmeans']=adata.obs['kmeans'].astype('category')\n",
    "seaborn.clustermap(pyro.param('locs').detach().cpu().numpy())\n",
    "plt.show()\n",
    "seaborn.clustermap(pyro.param('locs_dynam').detach().cpu().numpy())\n",
    "plt.show()\n",
    "antipode_model.train_phase_2(max_steps=max_steps,print_every=10000,num_particles=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2972a5-7bbe-466d-8593-e1094bcd9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.store_outputs(device=device,prefix='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd73994e-d00e-41e3-a40d-6257c24e53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.param('locs').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3c958-b69f-4b1f-ac3b-c6c45e8f4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmm_heatmaps(antipode_model)\n",
    "plot_tree_edge_weights(antipode_model)\n",
    "plot_d_hists(antipode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a782b8-a259-4f0c-8eba-dc8bd7e8295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDE_KEY = \"X_antipode_MDE\"\n",
    "adata.obsm[MDE_KEY] = scvi.model.utils.mde(adata.obsm['X_antipode'])\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"antipode_cluster\",\"kmeans\"],legend_fontsize=6,legend_fontweight='normal',\n",
    "    legend_loc='on data',palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"species\"],palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=['dataset'],palette=sc.pl.palettes.godsnot_102\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1cd5d-7a88-4052-8ad5-2354b786cc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sc.pl.umap(adata,color=[x for x in adata.obs.columns if 'level' in x]+['antipode_cluster','kmeans'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "random_choice=np.random.choice(adata.obs.index,size=10000,replace=False)\n",
    "random_choice=np.where(adata.obs.index.isin(random_choice))[0]\n",
    "xdata=adata[random_choice,:]\n",
    "xdata=xdata.to_memory().copy()\n",
    "sc.pp.neighbors(xdata,n_neighbors=20, use_rep=\"X_antipode\")\n",
    "sc.tl.umap(xdata)\n",
    "sc.pl.umap(xdata,color=['species'],use_raw=False,legend_loc='on data',palette=sc.pl.palettes.godsnot_102)\n",
    "sc.pl.umap(xdata,color=['psi'],use_raw=False,legend_loc='on data',cmap='coolwarm')\n",
    "sc.pl.umap(xdata,color=[x for x in adata.obs.columns if 'level' in x]+['antipode_cluster','kmeans'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "# xdata.X=xdata.layers['UMIs']\n",
    "# sc.pp.normalize_per_cell(xdata)\n",
    "# sc.pp.log1p(xdata)\n",
    "# sc.pp.scale(xdata,max_value=10)\n",
    "#sc.pl.umap(xdata,color=['GBX2','EOMES','SIX3','OTX2','FOXG1','RBFOX3','TH','PDGFRA','AQP4','FOXJ1','AIF1','TTR','MOG','COL1A2','CD34','COL4A1','NPY','NKX2-1','FOXP2','SATB2','RORB','FEZF2','EMX1'],use_raw=False,cmap='Purples')\n",
    "#sc.pl.umap(xdata,color=['DLX2','PROX1','SCGN','TSHZ1','MEIS2','NKX2-1','LHX6','CRABP1','TSHZ1','FOXG1','PDGFRA','AIF1','AQP4','EDNRB','FOXJ1','CD34','MKI67'],cmap='Purples',use_raw=False)\n",
    "#sc.pl.umap(xdata,color=['RPL7','RPS17','RPL13A','MEF2C'],cmap='Purples',use_raw=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8088c-0ca6-4224-b9c3-5d53125d74bb",
   "metadata": {},
   "source": [
    "# Training Phase 3: Refining the final tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8a556-5e56-4aa0-9c3d-f7514c48e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.train_phase_3(max_steps=max_steps,print_every=10000,num_particles=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304689d-821f-4521-b515-414283bef218",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipode_model.store_outputs(device=device,prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b70a9-0c3e-4615-ad65-9dd3b6c9b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmm_heatmaps(antipode_model)\n",
    "plot_tree_edge_weights(antipode_model)\n",
    "plot_d_hists(antipode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e5701-b786-4267-bb7b-db00eada2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDE_KEY = \"X_antipode_MDE\"\n",
    "adata.obsm[MDE_KEY] = scvi.model.utils.mde(adata.obsm['X_antipode'])\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"antipode_cluster\",\"kmeans\"],legend_fontsize=6,legend_fontweight='normal',\n",
    "    legend_loc='on data',palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"species\"],palette=sc.pl.palettes.godsnot_102\n",
    ")\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=['dataset'],palette=sc.pl.palettes.godsnot_102\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681dc00-a0ed-4de0-a31a-1dce75329b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mousemeta=pd.read_csv('/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/data/cortex_data/internal_mouse/VISp_multiome_metadata_mouse.csv')\n",
    "mousemeta.index=mousemeta['sample_id']\n",
    "adata.obs['AIT21_subclass']=mousemeta['subclass_label_AIT21_rc_map']\n",
    "kmeans_to_subclass=adata.obs.groupby('kmeans')['AIT21_subclass'].value_counts().unstack().idxmax(1).to_dict()\n",
    "adata.obs['est_AIT21_subclass']=adata.obs['kmeans'].replace(kmeans_to_subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3acebd-8220-45de-9581-8ccead8a509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"est_AIT21_subclass\"],\n",
    "    palette=sc.pl.palettes.godsnot_102,\n",
    "    legend_loc='on data'\n",
    ")\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=MDE_KEY,\n",
    "    color=[\"level_3\"],\n",
    "    palette=sc.pl.palettes.godsnot_102,\n",
    "    legend_loc='on data'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8b601-4c7a-42ff-aa31-509cb4585311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.umap(adata,color=[x for x in adata.obs.columns if 'level' in x]+['antipode_cluster','kmeans'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "\n",
    "random_choice=np.random.choice(adata.obs.index,size=100000,replace=False)\n",
    "random_choice=np.where(adata.obs.index.isin(random_choice))[0]\n",
    "xdata=adata[random_choice,:]\n",
    "xdata=xdata.to_memory().copy()\n",
    "sc.pp.neighbors(xdata,n_neighbors=20, use_rep=\"X_antipode\")\n",
    "sc.tl.umap(xdata)\n",
    "\n",
    "sc.pl.umap(xdata,color=['species'],use_raw=False,palette=sc.pl.palettes.godsnot_102)\n",
    "sc.pl.umap(xdata,color=['psi'],use_raw=False,cmap='coolwarm')\n",
    "sc.pl.umap(xdata,color=[x for x in adata.obs.columns if 'level' in x]+['antipode_cluster'],use_raw=False,legend_loc=None,palette=sc.pl.palettes.godsnot_102)\n",
    "# xdata.X=xdata.layers['UMIs'].todense()\n",
    "# sc.pp.normalize_per_cell(xdata)\n",
    "# sc.pp.log1p(xdata)\n",
    "# sc.pp.scale(xdata,max_value=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fa96e-bae9-44ce-9c9b-d14f6cea029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=['RBFOX3','PDGFRA','AQP4','FOXJ1','AIF1','MOG','COL1A2','CD34','COL4A1','NPY','FOXP2','SATB2','RORB','DLX2','PROX1','SCGN','TSHZ1','SLC17A7','TLE4',\n",
    "           'MEIS2','NKX2-1','LHX6','CRABP1','TSHZ1','FOXG1','PDGFRA','AIF1','AQP4','EDNRB','FOXJ1','CD34','MKI67','RPL7','RPS17','RPL13A','MEF2C']\n",
    "gene_list=[x for x in gene_list if x in xdata.var.index]\n",
    "sc.pl.umap(xdata,color=gene_list,cmap='Purples',use_raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1360aa7-5a6e-49ec-9eaf-1ff9b834fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.write_h5ad('/home/matthew.schmitz/Matthew/1.9.1_run.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce7ab84-d9f0-4a66-89cd-3abbef40d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata.obs['log_n_umi']=np.log10(xdata.X.sum(1)+1)\n",
    "sc.pl.violin(xdata,groupby='dataset',keys='log_n_umi',rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6113d76-a024-4a7f-a855-c75e54cb7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(xdata,color=[x for x in adata.obs.columns if 'level' in x][1:]+['antipode_cluster'],use_raw=False,legend_loc='on data',legend_fontsize=6,legend_fontweight='normal',palette=sc.pl.palettes.godsnot_102)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4580b-5d6a-4329-9565-1125105e5b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf959ed-19ca-4283-a47e-3cd2a2e5b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97dbc71-d9dc-4190-8f09-3234f2eb5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec062af-4058-4afc-9aec-6627fa9dd5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878318b2-7678-40f2-bfa7-5019db96397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "np.random.seed(0)\n",
    "data = adata.uns['param_store']['discov_di'].var(-1)[:,-antipode_model.level_sizes[-1]:]\n",
    "species = antipode_model.adata_manager.registry['field_registries']['discov_ind']['state_registry']['categorical_mapping']\n",
    "clusters = [f'Cluster_{i}' for i in range(data.shape[-1])]\n",
    "\n",
    "df = pd.DataFrame(data, index=species, columns=clusters)\n",
    "\n",
    "# Annotations for clusters (assuming each cluster has a unique color)\n",
    "cluster_colors = adata.uns['level_3_colors']\n",
    "cluster_lut = dict(zip(map(str, clusters), cluster_colors))\n",
    "cluster_colors = pd.Series(df.columns, index=df.columns).map(cluster_lut)\n",
    "cluster_colors=cluster_colors.fillna('white')\n",
    "\n",
    "# Annotations for predicted subclasses (assuming each subclass has a unique color)\n",
    "# Replace 'subclass_values' with your actual subclass values\n",
    "level_to_subclass=adata.obs.groupby('level_3')['AIT21_subclass'].value_counts().unstack().idxmax(1)\n",
    "level_to_subclass.index=list(level_to_subclass.index.astype(int))\n",
    "for k in range(antipode_model.level_sizes[-1]):\n",
    "    if k not in level_to_subclass.keys():\n",
    "        level_to_subclass[k]='nan'\n",
    "subclasses=[level_to_subclass[k] for k in range(antipode_model.level_sizes[-1])]\n",
    "subclass_colors = [sc.pl.palettes.godsnot_102[x%len(sc.pl.palettes.godsnot_102)] for x in range(len(sc.pl.palettes.godsnot_102))]#sns.color_palette(\"Set2\", len(subclasses))\n",
    "subclass_lut = dict(zip(subclasses, subclass_colors))\n",
    "subclass_lut['nan']='white'\n",
    "subclass_colors = pd.Series(subclasses, index=df.columns).map(subclass_lut)\n",
    "\n",
    "# Concatenate the color annotations into a single DataFrame\n",
    "# Assuming you want these annotations for rows (species)\n",
    "row_colors = pd.DataFrame({'Subclass': subclass_colors,'Cluster': cluster_colors})\n",
    "print(row_colors)\n",
    "\n",
    "# Create the clustermap\n",
    "g = sns.clustermap(df, col_colors=row_colors, figsize=(12, 8))\n",
    "\n",
    "# Create a legend for the colors\n",
    "for label, color in subclass_lut.items():\n",
    "    g.ax_col_dendrogram.bar(0, 0, color=color, label=label, linewidth=0)\n",
    "g.ax_col_dendrogram.legend(title=\"Predicted Subclasses\", loc=\"center\", bbox_to_anchor=(0.5, 1.15), ncol=3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f45daf-83c5-40e4-870a-c933dacfd451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf42a1-16c8-4b4d-87f5-49dfb2a89729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed5c4a-701f-4768-b738-4c5286d1a08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79c3ed-04f1-42d9-8f1b-a986dc7ed412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36573f63-de85-47b2-a0de-c581731381a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb85cef-b77b-4da5-a611-8c22e055e556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
